{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_dataset():\n",
    "    with tf.name_scope('traindata'):\n",
    "        matx = sio.loadmat('C://Users//59723//Desktop//hello//p00//day01.mat')\n",
    "        data = matx['data']\n",
    "        l_data = data['left']\n",
    "        r_data = data['right']\n",
    "        img_l = l_data[0,0]['image'][0,0].astype(np.float32)\n",
    "        gaz_l = l_data[0,0]['gaze'][0,0]\n",
    "        pos_l = l_data[0,0]['pose'][0,0]\n",
    "        img_r = r_data[0,0]['image'][0,0].astype(np.float32)\n",
    "        gaz_r = r_data[0,0]['gaze'][0,0]\n",
    "        pos_r = r_data[0,0]['pose'][0,0]\n",
    "        img_l = np.reshape(img_l, [-1, 36*60])\n",
    "        img_r = np.reshape(img_r, [-1, 36*60])\n",
    "        gazelr = np.concatenate((gaz_l, gaz_r), axis=1).astype(np.float32)\n",
    "        poselr = np.concatenate((pos_l, pos_r), axis=1).astype(np.float32)\n",
    "        gazeset = tf.data.Dataset.from_tensor_slices(\n",
    "            {\n",
    "                'img_l':img_l,\n",
    "                'img_r':img_r,\n",
    "                'gaze':gazelr,\n",
    "                'pose':poselr\n",
    "            }\n",
    "        )\n",
    "        gazeset = gazeset.shuffle(1000)\n",
    "        gazeset = gazeset.repeat()\n",
    "        gazeset = gazeset.batch(16)\n",
    "        iterator = gazeset.make_one_shot_iterator()\n",
    "        trainset = iterator.get_next()\n",
    "    return trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_dataset():\n",
    "    with tf.name_scope('testdata'):\n",
    "        matx = sio.loadmat('C://Users//59723//Desktop//hello//p00//day02.mat')\n",
    "        data = matx['data']\n",
    "        l_data = data['left']\n",
    "        r_data = data['right']\n",
    "        img_l = l_data[0,0]['image'][0,0].astype(np.float32)\n",
    "        gaz_l = l_data[0,0]['gaze'][0,0]\n",
    "        pos_l = l_data[0,0]['pose'][0,0]\n",
    "        img_r = r_data[0,0]['image'][0,0].astype(np.float32)\n",
    "        gaz_r = r_data[0,0]['gaze'][0,0]\n",
    "        pos_r = r_data[0,0]['pose'][0,0]\n",
    "        img_l = np.reshape(img_l, [-1, 36*60])\n",
    "        img_r = np.reshape(img_r, [-1, 36*60])\n",
    "        gazelr = np.concatenate((gaz_l, gaz_r), axis=1).astype(np.float32)\n",
    "        poselr = np.concatenate((pos_l, pos_r), axis=1).astype(np.float32)\n",
    "        gazeset = tf.data.Dataset.from_tensor_slices(\n",
    "            {\n",
    "                'img_l':img_l,\n",
    "                'img_r':img_r,\n",
    "                'gaze':gazelr,\n",
    "                'pose':poselr\n",
    "            }\n",
    "        )\n",
    "        gazeset = gazeset.shuffle(1000)\n",
    "        gazeset = gazeset.repeat()\n",
    "        gazeset = gazeset.batch(16)\n",
    "        iterator = gazeset.make_one_shot_iterator()\n",
    "        testset = iterator.get_next()\n",
    "    return testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1],\n",
    "                     padding='VALID', name='conv')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x, name='relu')\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME', name='pool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BaseNet(inputs):\n",
    "    with tf.name_scope('input_layer'):\n",
    "        input_layer = tf.reshape(inputs, [-1, 36, 60, 1])\n",
    "    with tf.name_scope('conv1'):\n",
    "        w1 = tf.Variable(tf.random_normal([3, 3, 1, 64]), name='w1')\n",
    "        b1 = tf.Variable(tf.random_normal([64]), name='b1')\n",
    "        conv1 = conv2d(input_layer, w1, b1, strides=1)\n",
    "    with tf.name_scope('conv2'):\n",
    "        w2 = tf.Variable(tf.random_normal([3, 3, 64, 64]), name='w2')\n",
    "        b2 = tf.Variable(tf.random_normal([64]), name='b2')\n",
    "        conv2 = conv2d(conv1, w2, b2, strides=1)\n",
    "    with tf.name_scope('maxpool1'):\n",
    "        pool1 = maxpool2d(conv2, k=2)\n",
    "    with tf.name_scope('conv3'):\n",
    "        w3 = tf.Variable(tf.random_normal([3, 3, 64, 128]), name='w3')\n",
    "        b3 = tf.Variable(tf.random_normal([128]), name='b3')\n",
    "        conv3 = conv2d(pool1, w3, b3, strides=1)\n",
    "    with tf.name_scope('conv4'):\n",
    "        w4 = tf.Variable(tf.random_normal([3, 3, 128, 128]), name='w4')\n",
    "        b4 = tf.Variable(tf.random_normal([128]), name='b4')\n",
    "        conv4 = conv2d(conv3, w4, b4, strides=1)\n",
    "    with tf.name_scope('maxpool2'):\n",
    "        pool2 = maxpool2d(conv4, k=2)\n",
    "    with tf.name_scope('conv5'):\n",
    "        w5 = tf.Variable(tf.random_normal([3, 3, 128, 256]), name='w5')\n",
    "        b5 = tf.Variable(tf.random_normal([256]), name='b5')\n",
    "        conv5 = conv2d(pool2, w5, b5, strides=1)\n",
    "    with tf.name_scope('conv6'):\n",
    "        w6 = tf.Variable(tf.random_normal([3, 3, 256, 256]), name='w6')\n",
    "        b6 = tf.Variable(tf.random_normal([256]), name='b6')\n",
    "        conv6 = conv2d(conv5, w6, b6, strides=1)\n",
    "    with tf.name_scope('maxpool3'):\n",
    "        pool3 = maxpool2d(conv6, k=2)\n",
    "    return pool3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AR-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ARNet(input_l, input_r, input_p):\n",
    "    with tf.name_scope('stream1'):\n",
    "        with tf.name_scope('basenet1'):\n",
    "            basenet1 = BaseNet(input_l)\n",
    "        with tf.name_scope('fc11'):\n",
    "            wd11 = tf.Variable(tf.random_normal([1*4*256, 1000]), name='wd11')\n",
    "            bd11 = tf.Variable(tf.random_normal([1000]), name='bd11')\n",
    "            fc11 = tf.reshape(basenet1, [-1, wd11.get_shape().as_list()[0]])\n",
    "            fc11 = tf.add(tf.matmul(fc11, wd11), bd11)\n",
    "            fc11 = tf.nn.relu(fc11)\n",
    "        with tf.name_scope('fc12'):\n",
    "            wd12 = tf.Variable(tf.random_normal([1000, 500]), name='wd12')\n",
    "            bd12 = tf.Variable(tf.random_normal([500]), name='bd12')\n",
    "            fc12 = tf.reshape(fc11, [-1, wd12.get_shape().as_list()[0]])\n",
    "            fc12 = tf.add(tf.matmul(fc12, wd12), bd12)\n",
    "            fc12 = tf.nn.relu(fc12)\n",
    "        st1 = fc12\n",
    "    with tf.name_scope('stream2'):\n",
    "        with tf.name_scope('basenet2'):\n",
    "            basenet2 = BaseNet(input_r)\n",
    "        with tf.name_scope('fc21'):\n",
    "            wd21 = tf.Variable(tf.random_normal([1*4*256, 1000]), name='wd21')\n",
    "            bd21 = tf.Variable(tf.random_normal([1000]), name='bd21')\n",
    "            fc21 = tf.reshape(basenet2, [-1, wd21.get_shape().as_list()[0]])\n",
    "            fc21 = tf.add(tf.matmul(fc21, wd21), bd21)\n",
    "            fc21 = tf.nn.relu(fc21)\n",
    "        with tf.name_scope('fc22'):\n",
    "            wd22 = tf.Variable(tf.random_normal([1000, 500]), name='wd22')\n",
    "            bd22 = tf.Variable(tf.random_normal([500]), name='bd22')\n",
    "            fc22 = tf.reshape(fc21, [-1, wd22.get_shape().as_list()[0]])\n",
    "            fc22 = tf.add(tf.matmul(fc22, wd22), bd22)\n",
    "            fc22 = tf.nn.relu(fc22)\n",
    "        st2 = fc22\n",
    "    with tf.name_scope('stream3_4'):\n",
    "        with tf.name_scope('basenet3'):\n",
    "            basenet3 = BaseNet(input_l)\n",
    "        with tf.name_scope('fc31'):\n",
    "            wd31 = tf.Variable(tf.random_normal([1*4*256, 500]), name='wd31')\n",
    "            bd31 = tf.Variable(tf.random_normal([500]), name='bd31')\n",
    "            fc31 = tf.reshape(basenet3, [-1, wd31.get_shape().as_list()[0]])\n",
    "            fc31 = tf.add(tf.matmul(fc31, wd31), bd31)\n",
    "            fc31 = tf.nn.relu(fc31)\n",
    "        with tf.name_scope('basenet4'):\n",
    "            basenet4 = BaseNet(input_r)\n",
    "        with tf.name_scope('fc41'):\n",
    "            wd41 = tf.Variable(tf.random_normal([1*4*256, 500]), name='wd41')\n",
    "            bd41 = tf.Variable(tf.random_normal([500]), name='bd41')\n",
    "            fc41 = tf.reshape(basenet4, [-1, wd41.get_shape().as_list()[0]])\n",
    "            fc41 = tf.add(tf.matmul(fc41, wd41), bd41)\n",
    "            fc41 = tf.nn.relu(fc41)\n",
    "        with tf.name_scope('merge'):\n",
    "            fc34 = tf.concat([fc31, fc41], axis=1)\n",
    "            wd34 = tf.Variable(tf.random_normal([1000, 500]), name='wd34')\n",
    "            bd34 = tf.Variable(tf.random_normal([500]), name='bd34')\n",
    "            fc34 = tf.reshape(fc34, [-1, wd34.get_shape().as_list()[0]])\n",
    "            fc34 = tf.add(tf.matmul(fc34, wd34), bd34)\n",
    "            fc34 = tf.nn.relu(fc34)\n",
    "        st34 = fc34\n",
    "    with tf.name_scope('3D_Gaze'):\n",
    "        st = tf.concat([st1, st2, st34, input_p], axis=1)\n",
    "        wd = tf.Variable(tf.random_normal([1506, 6]), name='wd')\n",
    "        bd = tf.Variable(tf.random_normal([6]), name='bd')\n",
    "        gaze = tf.add(tf.matmul(st, wd), bd)\n",
    "    return gaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tenlen(inputs):\n",
    "    with tf.name_scope('length'):\n",
    "        shape = inputs.get_shape().as_list()\n",
    "        lenth = tf.sqrt(tf.reduce_sum(tf.square(inputs),axis=1))\n",
    "        lenth = tf.reshape(lenth, [-1, 1])\n",
    "        lenth = tf.tile(lenth, [1, shape[1]])\n",
    "    return lenth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ENet(input_l, input_r):\n",
    "    with tf.name_scope('stream1'):\n",
    "        with tf.name_scope('basenet1'):\n",
    "            basenet1 = BaseNet(input_l)\n",
    "        with tf.name_scope('fc11'):\n",
    "            wd11 = tf.Variable(tf.random_normal([1*4*256, 1000]), name='wd11')\n",
    "            bd11 = tf.Variable(tf.random_normal([1000]), name='bd11')\n",
    "            fc11 = tf.reshape(basenet1, [-1, wd11.get_shape().as_list()[0]])\n",
    "            fc11 = tf.add(tf.matmul(fc11, wd11), bd11)\n",
    "            fc11 = tf.nn.relu(fc11)\n",
    "        with tf.name_scope('fc12'):\n",
    "            wd12 = tf.Variable(tf.random_normal([1000, 500]), name='wd12')\n",
    "            bd12 = tf.Variable(tf.random_normal([500]), name='bd12')\n",
    "            fc12 = tf.reshape(fc11, [-1, wd12.get_shape().as_list()[0]])\n",
    "            fc12 = tf.add(tf.matmul(fc12, wd12), bd12)\n",
    "            fc12 = tf.nn.relu(fc12)\n",
    "        st1 = fc12\n",
    "    with tf.name_scope('stream2'):\n",
    "        with tf.name_scope('basenet2'):\n",
    "            basenet2 = BaseNet(input_r)\n",
    "        with tf.name_scope('fc21'):\n",
    "            wd21 = tf.Variable(tf.random_normal([1*4*256, 1000]), name='wd21')\n",
    "            bd21 = tf.Variable(tf.random_normal([1000]), name='bd21')\n",
    "            fc21 = tf.reshape(basenet2, [-1, wd21.get_shape().as_list()[0]])\n",
    "            fc21 = tf.add(tf.matmul(fc21, wd21), bd21)\n",
    "            fc21 = tf.nn.relu(fc21)\n",
    "        with tf.name_scope('fc22'):\n",
    "            wd22 = tf.Variable(tf.random_normal([1000, 500]), name='wd22')\n",
    "            bd22 = tf.Variable(tf.random_normal([500]), name='bd22')\n",
    "            fc22 = tf.reshape(fc21, [-1, wd22.get_shape().as_list()[0]])\n",
    "            fc22 = tf.add(tf.matmul(fc22, wd22), bd22)\n",
    "            fc22 = tf.nn.relu(fc22)\n",
    "        st2 = fc22\n",
    "    with tf.name_scope('softmax'):\n",
    "        st = tf.concat([st1, st2], axis=1)\n",
    "        wd = tf.Variable(tf.random_normal([1000, 2]), name='wd')\n",
    "        bd = tf.Variable(tf.random_normal([2]), name='bd')\n",
    "        fc = tf.add(tf.matmul(st, wd), bd)\n",
    "        sf = tf.nn.softmax(fc, name='fun_softmax')\n",
    "    return sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 lare=7.345617\n",
      "    ang_loss=10.785369\n",
      "    e_l=12.429922 e_r=7.161823\n",
      "[ 1.8637333e-04  2.0173751e-01 -9.7943968e-01]\n",
      "[-0.18040155  0.08229099 -0.98014456]\n",
      "iter 2 lare=4.452359\n",
      "    ang_loss=7.703822\n",
      "    e_l=6.801436 e_r=6.227118\n",
      "[-0.01110249  0.12203338 -0.99246395]\n",
      "[-0.12676908  0.14587764 -0.9811471 ]\n",
      "iter 3 lare=2.888388\n",
      "    ang_loss=8.298311\n",
      "    e_l=13.671021 e_r=13.383117\n",
      "[ 0.07195368  0.25098142 -0.96531403]\n",
      "[-0.09815346  0.08652573 -0.9914027 ]\n",
      "iter 4 lare=6.911455\n",
      "    ang_loss=10.215003\n",
      "    e_l=12.848655 e_r=12.351715\n",
      "[ 0.15739444  0.11315145 -0.981032  ]\n",
      "[-0.05989055  0.06183949 -0.99628764]\n",
      "iter 5 lare=2.218468\n",
      "    ang_loss=8.559094\n",
      "    e_l=6.869212 e_r=9.170676\n",
      "[-0.01035973  0.22030288 -0.97537655]\n",
      "[-0.00702779  0.10210732 -0.9947486 ]\n",
      "iter 6 lare=3.357405\n",
      "    ang_loss=8.297204\n",
      "    e_l=4.020975 e_r=8.471064\n",
      "[ 0.14423662  0.15904003 -0.97667915]\n",
      "[ 0.10653075  0.10119604 -0.9891463 ]\n",
      "iter 7 lare=2.114450\n",
      "    ang_loss=10.931007\n",
      "    e_l=23.634459 e_r=14.136979\n",
      "[-0.22010969  0.12777641 -0.96707034]\n",
      "[ 0.18928857  0.11827803 -0.9747718 ]\n",
      "iter 8 lare=1.833159\n",
      "    ang_loss=14.158542\n",
      "    e_l=9.020968 e_r=2.639601\n",
      "[ 0.13586846  0.11882523 -0.98357534]\n",
      "[ 0.21888426  0.2464542  -0.9441133 ]\n",
      "iter 9 lare=1.298684\n",
      "    ang_loss=12.986841\n",
      "    e_l=17.173744 e_r=11.059535\n",
      "[-0.11586609  0.24582405 -0.9623646 ]\n",
      "[ 0.17210636  0.1672522  -0.97077596]\n",
      "iter 10 lare=1.839772\n",
      "    ang_loss=15.211325\n",
      "    e_l=19.622683 e_r=13.907448\n",
      "[-0.1365064   0.24992786 -0.95859385]\n",
      "[ 0.19843976  0.30648363 -0.9309616 ]\n",
      "iter 11 lare=1.196601\n",
      "    ang_loss=11.966013\n",
      "    e_l=13.987077 e_r=6.592045\n",
      "[-0.04549669  0.22651967 -0.9729435 ]\n",
      "[ 0.1959342   0.24733599 -0.94891244]\n",
      "iter 12 lare=1.419772\n",
      "    ang_loss=14.197716\n",
      "    e_l=17.914259 e_r=7.421851\n",
      "[-0.01501668  0.10397884 -0.9944662 ]\n",
      "[ 0.19799066  0.32064086 -0.926277  ]\n",
      "iter 13 lare=1.317908\n",
      "    ang_loss=13.179077\n",
      "    e_l=21.014427 e_r=11.904381\n",
      "[ 0.05122756  0.00708829 -0.99866194]\n",
      "[ 0.17910056  0.34020162 -0.9231391 ]\n",
      "iter 14 lare=1.109713\n",
      "    ang_loss=9.722319\n",
      "    e_l=19.551170 e_r=15.216990\n",
      "[-0.19397609  0.2309603  -0.95343107]\n",
      "[ 0.13307235  0.32099137 -0.9376867 ]\n",
      "iter 15 lare=1.254518\n",
      "    ang_loss=11.098005\n",
      "    e_l=5.675818 e_r=0.600683\n",
      "[ 0.11628651  0.23409525 -0.96523416]\n",
      "[ 0.166201    0.31400508 -0.9347611 ]\n",
      "iter 16 lare=1.476559\n",
      "    ang_loss=8.579913\n",
      "    e_l=3.113321 e_r=3.198798\n",
      "[ 0.08555107  0.18913195 -0.9782179 ]\n",
      "[ 0.07239874  0.24082221 -0.9678653 ]\n",
      "iter 17 lare=3.945260\n",
      "    ang_loss=12.748280\n",
      "    e_l=14.336030 e_r=12.562769\n",
      "[-0.14475198  0.24559425 -0.95850426]\n",
      "[ 0.10230952  0.21294077 -0.9716939 ]\n",
      "iter 18 lare=6.354111\n",
      "    ang_loss=9.525106\n",
      "    e_l=6.867299 e_r=8.026440\n",
      "[-0.04359567  0.0646134  -0.9969577 ]\n",
      "[ 0.00396909  0.17387226 -0.9847602 ]\n",
      "iter 19 lare=4.963973\n",
      "    ang_loss=7.914680\n",
      "    e_l=6.106085 e_r=3.583701\n",
      "[ 0.06669053  0.23305878 -0.97017324]\n",
      "[-0.00333962  0.15478384 -0.98794276]\n",
      "iter 20 lare=2.656089\n",
      "    ang_loss=8.163319\n",
      "    e_l=9.364686 e_r=8.687855\n",
      "[-0.09846282  0.2810691  -0.95462316]\n",
      "[-0.01630247  0.1443375  -0.98939425]\n",
      "iter 21 lare=3.510521\n",
      "    ang_loss=9.714968\n",
      "    e_l=10.044435 e_r=7.502448\n",
      "[ 0.03168431  0.26555187 -0.96357584]\n",
      "[-0.06353588  0.1211311  -0.99060106]\n",
      "iter 22 lare=2.288262\n",
      "    ang_loss=9.452179\n",
      "    e_l=6.767440 e_r=7.135149\n",
      "[-0.0585388   0.02317555 -0.9980161 ]\n",
      "[-0.14043644  0.10707357 -0.98428285]\n",
      "iter 23 lare=2.193220\n",
      "    ang_loss=10.065058\n",
      "    e_l=16.254610 e_r=13.890743\n",
      "[ 0.10618141  0.25024432 -0.9623427 ]\n",
      "[-0.12820242  0.09407742 -0.98727584]\n",
      "iter 24 lare=1.848772\n",
      "    ang_loss=10.852804\n",
      "    e_l=13.233974 e_r=12.945249\n",
      "[ 0.06091448  0.15763843 -0.9856164 ]\n",
      "[-0.12742317  0.02494562 -0.9915347 ]\n",
      "iter 25 lare=3.055107\n",
      "    ang_loss=12.019865\n",
      "    e_l=15.815133 e_r=12.858849\n",
      "[-0.2329431   0.24413855 -0.9413469 ]\n",
      "[-0.19359148 -0.02531702 -0.9807555 ]\n",
      "iter 26 lare=1.481065\n",
      "    ang_loss=14.810647\n",
      "    e_l=14.854712 e_r=14.057408\n",
      "[-0.04864671  0.23632482 -0.97045565]\n",
      "[-0.18203974  0.01522161 -0.9831734 ]\n",
      "iter 27 lare=2.764050\n",
      "    ang_loss=11.962492\n",
      "    e_l=9.487754 e_r=7.178732\n",
      "[-0.28399897  0.05860301 -0.9570321 ]\n",
      "[-0.19727618 -0.08081828 -0.97701097]\n",
      "iter 28 lare=3.760846\n",
      "    ang_loss=11.610369\n",
      "    e_l=6.816070 e_r=5.792680\n",
      "[-0.21279737  0.09362134 -0.9726009 ]\n",
      "[-0.20615521 -0.02495424 -0.97820103]\n",
      "iter 29 lare=3.274312\n",
      "    ang_loss=13.721990\n",
      "    e_l=17.433237 e_r=16.185114\n",
      "[ 0.07579473  0.24354719 -0.966923  ]\n",
      "[-0.12734285  0.01996238 -0.9916579 ]\n",
      "iter 30 lare=2.234285\n",
      "    ang_loss=10.847275\n",
      "    e_l=10.460534 e_r=11.200606\n",
      "[-0.20233765  0.22308394 -0.95356864]\n",
      "[-0.15405615  0.05043974 -0.9867738 ]\n",
      "iter 31 lare=1.836567\n",
      "    ang_loss=12.039570\n",
      "    e_l=12.634446 e_r=10.479496\n",
      "[ 0.08450137  0.05507313 -0.9949003 ]\n",
      "[-0.13446464  0.03356591 -0.99034977]\n",
      "iter 32 lare=3.948021\n",
      "    ang_loss=10.161762\n",
      "    e_l=15.205991 e_r=13.041532\n",
      "[ 0.08539588  0.16620353 -0.98238695]\n",
      "[-0.13824272  0.02496349 -0.9900838 ]\n",
      "iter 33 lare=1.806221\n",
      "    ang_loss=9.002944\n",
      "    e_l=13.454357 e_r=10.869117\n",
      "[-0.05699397  0.21161114 -0.9756908 ]\n",
      "[-0.15897244  0.00100502 -0.98728245]\n",
      "iter 34 lare=1.641625\n",
      "    ang_loss=9.314230\n",
      "    e_l=11.691367 e_r=10.960703\n",
      "[-0.2063285   0.23012196 -0.95103765]\n",
      "[-0.18015473  0.03068129 -0.98315966]\n",
      "iter 35 lare=2.378687\n",
      "    ang_loss=7.970296\n",
      "    e_l=12.451720 e_r=10.365437\n",
      "[ 0.07646827  0.2179434  -0.9729611 ]\n",
      "[-0.11869886  0.12410705 -0.9851436 ]\n",
      "iter 36 lare=2.305194\n",
      "    ang_loss=9.753960\n",
      "    e_l=3.303279 e_r=4.325584\n",
      "[-0.2418348   0.13166112 -0.9613435 ]\n",
      "[-0.19234762  0.10577068 -0.97560996]\n",
      "iter 37 lare=1.218395\n",
      "    ang_loss=10.181500\n",
      "    e_l=11.290304 e_r=10.157084\n",
      "[-0.02752114  0.08114826 -0.9963221 ]\n",
      "[-0.20950224  0.14960243 -0.966296  ]\n",
      "iter 38 lare=2.468764\n",
      "    ang_loss=12.009369\n",
      "    e_l=13.260397 e_r=11.863286\n",
      "[ 0.05728036  0.20631294 -0.9768081 ]\n",
      "[-0.17046063  0.16858725 -0.9708355 ]\n",
      "iter 39 lare=1.389788\n",
      "    ang_loss=11.527319\n",
      "    e_l=5.108295 e_r=4.231932\n",
      "[-0.21959332  0.21425495 -0.951774  ]\n",
      "[-0.20612632  0.12807907 -0.9701071 ]\n",
      "iter 40 lare=1.118933\n",
      "    ang_loss=11.189333\n",
      "    e_l=15.594161 e_r=13.567526\n",
      "[ 0.07414925  0.19875139 -0.977241  ]\n",
      "[-0.19604352  0.21328054 -0.95711976]\n",
      "iter 41 lare=2.065961\n",
      "    ang_loss=9.399965\n",
      "    e_l=21.057344 e_r=18.785042\n",
      "[ 0.17534265  0.01895011 -0.9843251 ]\n",
      "[-0.14548619  0.1933898  -0.9702754 ]\n",
      "iter 42 lare=1.556022\n",
      "    ang_loss=13.576762\n",
      "    e_l=8.157453 e_r=7.819139\n",
      "[-0.2659517   0.08154158 -0.96053153]\n",
      "[-0.22355334  0.2169407  -0.9502424 ]\n",
      "iter 43 lare=2.409811\n",
      "    ang_loss=11.242622\n",
      "    e_l=13.003810 e_r=11.687912\n",
      "[ 0.06491064  0.25694004 -0.9642451 ]\n",
      "[-0.15051101  0.18735564 -0.97069275]\n",
      "iter 44 lare=3.514609\n",
      "    ang_loss=10.953243\n",
      "    e_l=15.948788 e_r=14.919062\n",
      "[ 0.09575342  0.20766795 -0.9735016 ]\n",
      "[-0.17707194  0.15719865 -0.9715627 ]\n",
      "iter 45 lare=3.054591\n",
      "    ang_loss=8.758324\n",
      "    e_l=0.920261 e_r=1.824026\n",
      "[-0.21907656  0.08302654 -0.9721688 ]\n",
      "[-0.22026731  0.09895528 -0.97040725]\n",
      "iter 46 lare=0.773416\n",
      "    ang_loss=7.734156\n",
      "    e_l=6.106374 e_r=5.625526\n",
      "[-0.19727565  0.22148198 -0.95500165]\n",
      "[-0.1979334   0.11653466 -0.97326356]\n",
      "iter 47 lare=1.036121\n",
      "    ang_loss=10.361214\n",
      "    e_l=14.482627 e_r=12.951345\n",
      "[ 0.15207168  0.2356134  -0.95987535]\n",
      "[-0.07644957  0.13299288 -0.9881641 ]\n",
      "iter 48 lare=1.989652\n",
      "    ang_loss=6.628801\n",
      "    e_l=16.502846 e_r=15.939326\n",
      "[ 0.16746373  0.17653185 -0.9699446 ]\n",
      "[-0.0943218   0.06122842 -0.9936571 ]\n",
      "iter 49 lare=2.142700\n",
      "    ang_loss=7.214757\n",
      "    e_l=0.827562 e_r=1.265477\n",
      "[-0.058485    0.12153435 -0.9908628 ]\n",
      "[-0.05698981  0.10726723 -0.99259555]\n",
      "iter 50 lare=3.629211\n",
      "    ang_loss=5.876278\n",
      "    e_l=5.054817 e_r=3.009799\n",
      "[ 0.07476723  0.10722563 -0.9914195 ]\n",
      "[-0.01042405  0.08493851 -0.9963317 ]\n",
      "iter 51 lare=3.477596\n",
      "    ang_loss=6.398902\n",
      "    e_l=8.279983 e_r=8.909069\n",
      "[-0.1902444   0.18753503 -0.9636586 ]\n",
      "[-0.07333019  0.10751042 -0.9914959 ]\n",
      "iter 52 lare=2.542980\n",
      "    ang_loss=7.259333\n",
      "    e_l=7.363325 e_r=6.670739\n",
      "[-0.01264612  0.20788798 -0.978071  ]\n",
      "[-0.09472116  0.10976568 -0.98943394]\n",
      "iter 53 lare=4.284655\n",
      "    ang_loss=6.938982\n",
      "    e_l=5.804140 e_r=6.383773\n",
      "[-0.02852626  0.25591782 -0.9662776 ]\n",
      "[-0.09691565  0.18224499 -0.9784652 ]\n",
      "iter 54 lare=1.927015\n",
      "    ang_loss=9.287497\n",
      "    e_l=11.301044 e_r=8.932061\n",
      "[-0.16407496 -0.00511171 -0.9864347 ]\n",
      "[-0.17117521  0.19068111 -0.9666126 ]\n",
      "iter 55 lare=2.384993\n",
      "    ang_loss=8.396456\n",
      "    e_l=3.296753 e_r=4.141937\n",
      "[-0.12707984  0.2288537  -0.96513045]\n",
      "[-0.15319288  0.17805547 -0.9720227 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 56 lare=1.467034\n",
      "    ang_loss=8.702652\n",
      "    e_l=1.658002 e_r=3.428626\n",
      "[-0.136148    0.25400487 -0.95757264]\n",
      "[-0.13715704  0.22591154 -0.96444386]\n",
      "iter 57 lare=0.876468\n",
      "    ang_loss=8.764680\n",
      "    e_l=17.147820 e_r=14.673045\n",
      "[ 0.14179234  0.08191883 -0.9865011 ]\n",
      "[-0.08561659  0.27269244 -0.95828414]\n",
      "iter 58 lare=1.778693\n",
      "    ang_loss=12.443648\n",
      "    e_l=14.560532 e_r=11.558648\n",
      "[-0.03216054  0.06857952 -0.99712723]\n",
      "[-0.12984413  0.2968036  -0.9460699 ]\n",
      "iter 59 lare=1.217556\n",
      "    ang_loss=12.175558\n",
      "    e_l=13.431823 e_r=10.575943\n",
      "[ 0.05582704  0.14019574 -0.98854876]\n",
      "[-0.11951814  0.28998947 -0.94953746]\n",
      "iter 60 lare=1.842241\n",
      "    ang_loss=12.119143\n",
      "    e_l=17.143127 e_r=15.599497\n",
      "[ 0.15671179  0.21674208 -0.96356857]\n",
      "[-0.13241972  0.28769162 -0.94852436]\n",
      "iter 61 lare=1.533708\n",
      "    ang_loss=11.649793\n",
      "    e_l=12.571198 e_r=10.613575\n",
      "[-0.12529774  0.04399159 -0.99114347]\n",
      "[-0.14635165  0.25888744 -0.9547557 ]\n",
      "iter 62 lare=1.156052\n",
      "    ang_loss=11.560518\n",
      "    e_l=9.245924 e_r=9.067286\n",
      "[-0.25411135  0.15864111 -0.95407575]\n",
      "[-0.14886609  0.2805988  -0.9482106 ]\n",
      "iter 63 lare=1.254059\n",
      "    ang_loss=12.540586\n",
      "    e_l=13.087686 e_r=10.862993\n",
      "[-0.11854336  0.07315644 -0.99025035]\n",
      "[-0.11450478  0.297089   -0.9479592 ]\n",
      "iter 64 lare=1.339917\n",
      "    ang_loss=13.399170\n",
      "    e_l=19.819748 e_r=17.903553\n",
      "[-0.26100582 -0.00263614 -0.9653337 ]\n",
      "[-0.13413486  0.31625244 -0.9391443 ]\n",
      "iter 65 lare=1.865322\n",
      "    ang_loss=9.853184\n",
      "    e_l=7.046341 e_r=4.867115\n",
      "[ 0.04611765  0.23568392 -0.97073495]\n",
      "[-0.06807017  0.27926785 -0.9577975 ]\n",
      "iter 66 lare=1.454338\n",
      "    ang_loss=10.172549\n",
      "    e_l=15.949794 e_r=12.524636\n",
      "[-0.00521976  0.01642299 -0.9998516 ]\n",
      "[-0.08476462  0.27871788 -0.956625  ]\n",
      "iter 67 lare=2.659405\n",
      "    ang_loss=11.005936\n",
      "    e_l=15.034994 e_r=11.746551\n",
      "[ 0.11932111  0.0766139  -0.9898954 ]\n",
      "[-0.05417896  0.27036902 -0.9612311 ]\n",
      "iter 68 lare=1.026158\n",
      "    ang_loss=8.425135\n",
      "    e_l=10.379131 e_r=9.525346\n",
      "[-0.20824733  0.09575716 -0.97337747]\n",
      "[-0.08059956  0.22392678 -0.9712675 ]\n",
      "iter 69 lare=1.595446\n",
      "    ang_loss=8.281950\n",
      "    e_l=4.919084 e_r=4.990572\n",
      "[-0.21909305  0.20689562 -0.9535159 ]\n",
      "[-0.13560817  0.22291465 -0.9653598 ]\n",
      "iter 70 lare=1.994605\n",
      "    ang_loss=7.834449\n",
      "    e_l=11.828282 e_r=9.556972\n",
      "[-0.04011397  0.03038986 -0.9987329 ]\n",
      "[-0.09120152  0.22786853 -0.9694113 ]\n",
      "iter 71 lare=1.626755\n",
      "    ang_loss=8.996889\n",
      "    e_l=1.318786 e_r=1.071737\n",
      "[-0.08573159  0.18903485 -0.9782209 ]\n",
      "[-0.09537576  0.20932458 -0.9731839 ]\n",
      "iter 72 lare=1.963027\n",
      "    ang_loss=7.946253\n",
      "    e_l=3.693266 e_r=3.437352\n",
      "[-0.10835962  0.19780606 -0.97423357]\n",
      "[-0.06818446  0.14892562 -0.98649484]\n",
      "iter 73 lare=1.495564\n",
      "    ang_loss=8.610970\n",
      "    e_l=4.458828 e_r=3.994833\n",
      "[-0.10402549  0.24383196 -0.9642224 ]\n",
      "[-0.08412841  0.1706821  -0.9817281 ]\n",
      "iter 74 lare=2.015786\n",
      "    ang_loss=8.115601\n",
      "    e_l=5.320197 e_r=4.892087\n",
      "[-0.13578522  0.25421742 -0.95756775]\n",
      "[-0.09948299  0.17181109 -0.98009396]\n",
      "iter 75 lare=2.171790\n",
      "    ang_loss=8.571999\n",
      "    e_l=10.790360 e_r=9.692416\n",
      "[ 0.14179234  0.08191883 -0.9865011 ]\n",
      "[-0.0218273   0.17458454 -0.9844003 ]\n",
      "iter 76 lare=2.436574\n",
      "    ang_loss=8.116545\n",
      "    e_l=9.877727 e_r=9.129098\n",
      "[-0.02886102  0.27346757 -0.9614482 ]\n",
      "[-0.1292191   0.13512537 -0.9823663 ]\n",
      "iter 77 lare=1.741059\n",
      "    ang_loss=7.129262\n",
      "    e_l=6.375351 e_r=6.320186\n",
      "[-0.14578336  0.26038682 -0.95443493]\n",
      "[-0.07997128  0.17486763 -0.9813388 ]\n",
      "iter 78 lare=1.464111\n",
      "    ang_loss=5.472464\n",
      "    e_l=4.073811 e_r=2.928172\n",
      "[-0.01130274  0.18544191 -0.98259026]\n",
      "[-0.04255502  0.12223022 -0.99158907]\n",
      "iter 79 lare=2.112816\n",
      "    ang_loss=8.156321\n",
      "    e_l=8.846066 e_r=8.344402\n",
      "[ 0.14902945  0.13358818 -0.9797676 ]\n",
      "[-0.0032381  0.1132335 -0.9935631]\n",
      "iter 80 lare=1.400034\n",
      "    ang_loss=7.978368\n",
      "    e_l=10.242634 e_r=9.696209\n",
      "[ 0.01080015  0.28023234 -0.95987153]\n",
      "[-0.03893144  0.11198891 -0.9929465 ]\n",
      "iter 81 lare=3.032185\n",
      "    ang_loss=6.987301\n",
      "    e_l=11.158385 e_r=10.728713\n",
      "[-0.09846282  0.2810691  -0.95462316]\n",
      "[-0.0457308   0.09812811 -0.99412256]\n",
      "iter 82 lare=1.760070\n",
      "    ang_loss=6.252291\n",
      "    e_l=4.458214 e_r=3.969705\n",
      "[ 0.060689    0.15620019 -0.9858593 ]\n",
      "[-0.01286893  0.13146156 -0.99123776]\n",
      "iter 83 lare=1.222791\n",
      "    ang_loss=7.372141\n",
      "    e_l=6.187828 e_r=5.160271\n",
      "[-0.18264873  0.14886038 -0.97184366]\n",
      "[-0.07709865  0.13313192 -0.988095  ]\n",
      "iter 84 lare=1.956930\n",
      "    ang_loss=7.176843\n",
      "    e_l=8.859181 e_r=5.794338\n",
      "[-0.19016743  0.10927694 -0.9756511 ]\n",
      "[-0.05449167  0.03882262 -0.9977592 ]\n",
      "iter 85 lare=2.394419\n",
      "    ang_loss=5.566271\n",
      "    e_l=4.678265 e_r=5.385724\n",
      "[ 0.067656    0.09921479 -0.9927634 ]\n",
      "[ 0.02164865  0.03210026 -0.9992501 ]\n",
      "iter 86 lare=2.837156\n",
      "    ang_loss=8.406271\n",
      "    e_l=6.687797 e_r=6.173046\n",
      "[ 0.17083724  0.09858158 -0.98035526]\n",
      "[ 0.05521334  0.09172992 -0.99425197]\n",
      "iter 87 lare=1.369133\n",
      "    ang_loss=6.255144\n",
      "    e_l=7.866914 e_r=6.253478\n",
      "[-0.01684394  0.2365726  -0.97146785]\n",
      "[ 0.03265201  0.11049925 -0.99333966]\n",
      "iter 88 lare=0.956105\n",
      "    ang_loss=7.838759\n",
      "    e_l=7.835539 e_r=6.840083\n",
      "[-0.04146668  0.02386348 -0.99885494]\n",
      "[ 0.09053817  0.05887404 -0.99415123]\n",
      "iter 89 lare=1.745195\n",
      "    ang_loss=9.996119\n",
      "    e_l=14.508387 e_r=11.475795\n",
      "[-0.15195014  0.18072459 -0.9717252 ]\n",
      "[ 0.06368439  0.05165273 -0.9966325 ]\n",
      "iter 90 lare=1.606138\n",
      "    ang_loss=10.580134\n",
      "    e_l=5.202963 e_r=2.516840\n",
      "[ 0.05161209  0.1427066  -0.9884185 ]\n",
      "[ 0.11159708  0.07461722 -0.9909482 ]\n",
      "iter 91 lare=0.988820\n",
      "    ang_loss=9.888204\n",
      "    e_l=4.569990 e_r=1.994392\n",
      "[ 0.08419588  0.14699635 -0.9855472 ]\n",
      "[ 0.1260721   0.07921705 -0.9888531 ]\n",
      "iter 92 lare=1.348354\n",
      "    ang_loss=9.911841\n",
      "    e_l=17.454414 e_r=14.379042\n",
      "[-0.22334374  0.08001557 -0.97145003]\n",
      "[ 0.07927995  0.07753014 -0.9938328 ]\n",
      "iter 93 lare=1.447599\n",
      "    ang_loss=11.249651\n",
      "    e_l=4.481919 e_r=8.201547\n",
      "[ 0.15243773 -0.00101403 -0.9883126 ]\n",
      "[ 0.0920799   0.04831818 -0.9945786 ]\n",
      "iter 94 lare=1.103461\n",
      "    ang_loss=11.034615\n",
      "    e_l=12.692009 e_r=7.732104\n",
      "[-0.11366582  0.12153649 -0.98605734]\n",
      "[ 0.08141313  0.01807362 -0.9965166 ]\n",
      "iter 95 lare=1.306809\n",
      "    ang_loss=11.864257\n",
      "    e_l=22.215086 e_r=14.984359\n",
      "[-0.11826238  0.25737754 -0.9590469 ]\n",
      "[ 0.15030095 -0.01733098 -0.9884883 ]\n",
      "iter 96 lare=1.443690\n",
      "    ang_loss=10.061693\n",
      "    e_l=13.322829 e_r=8.750281\n",
      "[ 0.08555107  0.18913195 -0.9782179 ]\n",
      "[ 0.17055857 -0.02663164 -0.9849877 ]\n",
      "iter 97 lare=1.581225\n",
      "    ang_loss=9.387669\n",
      "    e_l=9.654777 e_r=5.851261\n",
      "[ 0.08747622  0.17937706 -0.9798836 ]\n",
      "[ 0.12763433  0.01635616 -0.9916864 ]\n",
      "iter 98 lare=1.524397\n",
      "    ang_loss=9.545016\n",
      "    e_l=14.444985 e_r=7.786438\n",
      "[-0.03951065  0.20477213 -0.97801197]\n",
      "[ 0.10009361 -0.00366969 -0.9949713 ]\n",
      "iter 99 lare=1.331933\n",
      "    ang_loss=13.319328\n",
      "    e_l=18.721199 e_r=11.364009\n",
      "[-0.11586609  0.24582405 -0.9623646 ]\n",
      "[ 0.09128292 -0.00274575 -0.99582124]\n",
      "iter 100 lare=1.155874\n",
      "    ang_loss=7.580232\n",
      "    e_l=7.283460 e_r=3.513685\n",
      "[-0.04847037  0.12001725 -0.99158794]\n",
      "[ 0.06977274  0.07369308 -0.99483716]\n",
      "iter 101 lare=1.042904\n",
      "    ang_loss=7.701422\n",
      "    e_l=6.256299 e_r=2.806376\n",
      "[ 0.03962926  0.19794783 -0.9794112 ]\n",
      "[ 0.07686792  0.09618172 -0.99239135]\n",
      "iter 102 lare=1.993058\n",
      "    ang_loss=7.469388\n",
      "    e_l=10.946181 e_r=6.062006\n",
      "[-0.11484929  0.2007018  -0.972897  ]\n",
      "[ 0.02539625  0.07365732 -0.9969602 ]\n",
      "iter 103 lare=1.940902\n",
      "    ang_loss=8.433064\n",
      "    e_l=8.412278 e_r=4.932487\n",
      "[-0.04670739  0.19618088 -0.97945476]\n",
      "[ 0.05066349  0.087555   -0.9948706 ]\n",
      "iter 104 lare=2.484989\n",
      "    ang_loss=8.918089\n",
      "    e_l=10.111590 e_r=7.083465\n",
      "[-0.12529774  0.04399159 -0.99114347]\n",
      "[ 0.04322358  0.09550926 -0.9944896 ]\n",
      "iter 105 lare=1.750958\n",
      "    ang_loss=8.093040\n",
      "    e_l=9.398541 e_r=8.391102\n",
      "[ 0.10455667  0.02309281 -0.99425083]\n",
      "[-4.1535194e-04  1.4878806e-01 -9.8886895e-01]\n",
      "iter 106 lare=1.782013\n",
      "    ang_loss=6.061014\n",
      "    e_l=10.183060 e_r=8.981219\n",
      "[-0.20291364  0.08870474 -0.97517055]\n",
      "[-0.03334612  0.13909715 -0.98971707]\n",
      "iter 107 lare=1.687451\n",
      "    ang_loss=6.977480\n",
      "    e_l=1.728164 e_r=1.560472\n",
      "[-0.00169931  0.11936476 -0.99284905]\n",
      "[ 0.00208748  0.14901797 -0.9888323 ]\n",
      "iter 108 lare=2.247983\n",
      "    ang_loss=6.894640\n",
      "    e_l=12.253658 e_r=10.467529\n",
      "[-0.21167798  0.01918526 -0.9771512 ]\n",
      "[-0.0665961   0.17568117 -0.982192  ]\n",
      "iter 109 lare=0.982706\n",
      "    ang_loss=8.355074\n",
      "    e_l=2.061845 e_r=3.676954\n",
      "[ 1.8637333e-04  2.0173751e-01 -9.7943968e-01]\n",
      "[-0.03568988  0.20428117 -0.9782614 ]\n",
      "iter 110 lare=1.473434\n",
      "    ang_loss=7.967750\n",
      "    e_l=10.313796 e_r=7.422882\n",
      "[-0.00742609  0.01630399 -0.99983954]\n",
      "[ 6.1993173e-04  1.9488153e-01 -9.8082656e-01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 111 lare=0.793866\n",
      "    ang_loss=7.938656\n",
      "    e_l=3.728776 e_r=3.605869\n",
      "[-0.16641884  0.2363705  -0.95730555]\n",
      "[-0.10343197  0.224856   -0.96888685]\n",
      "iter 112 lare=1.756334\n",
      "    ang_loss=7.083865\n",
      "    e_l=10.581449 e_r=7.530356\n",
      "[-0.2391965   0.06382737 -0.9688711 ]\n",
      "[-0.1402192   0.21939978 -0.9655063 ]\n",
      "iter 113 lare=1.675237\n",
      "    ang_loss=9.186295\n",
      "    e_l=14.278016 e_r=11.947201\n",
      "[ 0.18178912  0.23543069 -0.9547383 ]\n",
      "[-0.06631982  0.2422874  -0.96793514]\n",
      "iter 114 lare=1.086508\n",
      "    ang_loss=7.891042\n",
      "    e_l=9.571565 e_r=6.013532\n",
      "[-0.21050951  0.1140641  -0.97091466]\n",
      "[-0.1167131   0.25169238 -0.96074396]\n",
      "iter 115 lare=1.917615\n",
      "    ang_loss=9.156017\n",
      "    e_l=11.767216 e_r=8.102901\n",
      "[-0.23211578  0.09251077 -0.96827894]\n",
      "[-0.09973934  0.24898343 -0.9633583 ]\n",
      "iter 116 lare=1.868302\n",
      "    ang_loss=8.977322\n",
      "    e_l=13.001837 e_r=10.221543\n",
      "[-0.07479084  0.01161125 -0.9971317 ]\n",
      "[-0.04112214  0.23404434 -0.9713559 ]\n",
      "iter 117 lare=0.949902\n",
      "    ang_loss=9.499023\n",
      "    e_l=10.039206 e_r=8.323078\n",
      "[ 0.13246387  0.11842682 -0.98408765]\n",
      "[ 0.00525549  0.23791085 -0.97127277]\n",
      "iter 118 lare=1.387797\n",
      "    ang_loss=6.758712\n",
      "    e_l=10.404577 e_r=7.472151\n",
      "[-0.16374743  0.0549073  -0.98497313]\n",
      "[-0.07241856  0.2112419  -0.9747474 ]\n",
      "iter 119 lare=1.680721\n",
      "    ang_loss=7.144993\n",
      "    e_l=8.913214 e_r=7.066274\n",
      "[ 0.14083     0.2575149  -0.95595664]\n",
      "[-0.00587957  0.21098411 -0.97747177]\n",
      "iter 120 lare=1.728729\n",
      "    ang_loss=8.067072\n",
      "    e_l=9.230076 e_r=8.910105\n",
      "[-0.251563    0.21443991 -0.94378585]\n",
      "[-0.09469867  0.19787703 -0.97564167]\n",
      "iter 121 lare=2.719131\n",
      "    ang_loss=7.473325\n",
      "    e_l=10.804652 e_r=9.648197\n",
      "[-0.24140446  0.06964222 -0.9679225 ]\n",
      "[-0.07881586  0.16334936 -0.98341495]\n",
      "iter 122 lare=1.346076\n",
      "    ang_loss=7.868451\n",
      "    e_l=12.314926 e_r=10.323291\n",
      "[-0.22707735  0.03113022 -0.97337914]\n",
      "[-0.05442037  0.15782316 -0.9859666 ]\n",
      "iter 123 lare=1.120510\n",
      "    ang_loss=6.903089\n",
      "    e_l=9.206242 e_r=6.398499\n",
      "[-0.175405    0.15797263 -0.9717396 ]\n",
      "[-0.01752988  0.13597697 -0.99055696]\n",
      "iter 124 lare=1.272923\n",
      "    ang_loss=5.538825\n",
      "    e_l=4.745614 e_r=4.530645\n",
      "[-0.01867633  0.05194464 -0.9984754 ]\n",
      "[-0.05496943  0.12594363 -0.99051327]\n",
      "iter 125 lare=1.442475\n",
      "    ang_loss=7.066383\n",
      "    e_l=6.639355 e_r=5.634125\n",
      "[-0.14030528  0.19705263 -0.9703014 ]\n",
      "[-0.07283347  0.10540102 -0.991759  ]\n",
      "iter 126 lare=1.665749\n",
      "    ang_loss=8.114891\n",
      "    e_l=8.861909 e_r=5.265405\n",
      "[-0.23942925  0.08619627 -0.9670801 ]\n",
      "[-0.08904228  0.06311332 -0.9940263 ]\n",
      "iter 127 lare=1.341629\n",
      "    ang_loss=7.421774\n",
      "    e_l=6.532759 e_r=7.407640\n",
      "[ 0.12210953  0.05977844 -0.99071485]\n",
      "[ 0.00843115  0.05739159 -0.9983162 ]\n",
      "iter 128 lare=2.016518\n",
      "    ang_loss=9.260235\n",
      "    e_l=2.386631 e_r=4.832213\n",
      "[-0.08831579  0.00843997 -0.99605685]\n",
      "[-0.05814436  0.03711349 -0.997618  ]\n",
      "iter 129 lare=1.030617\n",
      "    ang_loss=8.048488\n",
      "    e_l=14.438356 e_r=10.608103\n",
      "[ 0.10402697  0.24195655 -0.96469456]\n",
      "[-0.03424525  0.03487094 -0.99880487]\n",
      "iter 130 lare=1.586844\n",
      "    ang_loss=8.691074\n",
      "    e_l=12.398167 e_r=9.267961\n",
      "[-0.08687028  0.26145017 -0.9612999 ]\n",
      "[-0.09082706  0.04811837 -0.99470353]\n",
      "iter 131 lare=1.176529\n",
      "    ang_loss=8.641270\n",
      "    e_l=11.706558 e_r=6.372983\n",
      "[ 0.14902945  0.13358818 -0.9797676 ]\n",
      "[-0.01111946  0.00889721 -0.9998985 ]\n",
      "iter 132 lare=1.663202\n",
      "    ang_loss=8.027786\n",
      "    e_l=9.363909 e_r=8.703148\n",
      "[-0.18468487  0.1922317  -0.9638146 ]\n",
      "[-0.1204989   0.04474347 -0.99170464]\n",
      "iter 133 lare=1.314692\n",
      "    ang_loss=7.197850\n",
      "    e_l=5.472818 e_r=2.669758\n",
      "[-0.09711187  0.13239892 -0.98642784]\n",
      "[-0.09684803  0.03726676 -0.9946013 ]\n",
      "iter 134 lare=1.629900\n",
      "    ang_loss=7.898331\n",
      "    e_l=11.214890 e_r=9.713611\n",
      "[-0.04549669  0.22651967 -0.9729435 ]\n",
      "[-0.00920716  0.03631104 -0.9992981 ]\n",
      "iter 135 lare=1.028263\n",
      "    ang_loss=7.276165\n",
      "    e_l=12.630167 e_r=10.339171\n",
      "[-0.11826238  0.25737754 -0.9590469 ]\n",
      "[-0.05963498  0.04877054 -0.9970281 ]\n",
      "iter 136 lare=1.435931\n",
      "    ang_loss=9.354908\n",
      "    e_l=7.416932 e_r=6.903108\n",
      "[-0.04094569  0.14091805 -0.98917425]\n",
      "[-0.128227    0.04545175 -0.9907028 ]\n",
      "iter 137 lare=0.895430\n",
      "    ang_loss=8.888374\n",
      "    e_l=14.149040 e_r=10.820545\n",
      "[ 0.02474755  0.25614527 -0.9663215 ]\n",
      "[-0.12185074  0.05971199 -0.9907507 ]\n",
      "iter 138 lare=1.418998\n",
      "    ang_loss=8.030777\n",
      "    e_l=5.168959 e_r=5.838181\n",
      "[-0.00232309  0.00483418 -0.9999857 ]\n",
      "[-0.08092069  0.04883529 -0.9955235 ]\n",
      "iter 139 lare=1.580085\n",
      "    ang_loss=8.442898\n",
      "    e_l=15.314205 e_r=14.033655\n",
      "[ 0.09718851  0.2548499  -0.96208423]\n",
      "[-0.07759634  0.05646218 -0.9953848 ]\n",
      "iter 140 lare=0.933387\n",
      "    ang_loss=9.333868\n",
      "    e_l=4.064185 e_r=3.798750\n",
      "[-0.08851962  0.11478231 -0.98943895]\n",
      "[-0.12083576  0.05168182 -0.9913262 ]\n",
      "iter 141 lare=2.048142\n",
      "    ang_loss=6.724998\n",
      "    e_l=12.015587 e_r=8.001601\n",
      "[ 0.16939287  0.09811447 -0.9806527 ]\n",
      "[-0.03698222  0.06715897 -0.99705666]\n",
      "iter 142 lare=1.524029\n",
      "    ang_loss=6.469968\n",
      "    e_l=7.905519 e_r=4.351407\n",
      "[ 0.06632412  0.1280999  -0.9895411 ]\n",
      "[-0.05359917  0.06046453 -0.9967303 ]\n",
      "iter 143 lare=1.272848\n",
      "    ang_loss=6.371209\n",
      "    e_l=8.418812 e_r=3.902492\n",
      "[ 0.09076378  0.10413017 -0.99041355]\n",
      "[-0.05281181  0.07399534 -0.9958593 ]\n",
      "iter 144 lare=1.243503\n",
      "    ang_loss=5.492356\n",
      "    e_l=6.633001 e_r=5.018524\n",
      "[-0.1902444   0.18753503 -0.9636586 ]\n",
      "[-0.12365363  0.09601155 -0.98766977]\n",
      "iter 145 lare=0.812184\n",
      "    ang_loss=6.517880\n",
      "    e_l=10.358050 e_r=7.576212\n",
      "[ 0.09024245  0.17888923 -0.9797219 ]\n",
      "[-0.04683439  0.06266963 -0.99693483]\n",
      "iter 146 lare=0.937412\n",
      "    ang_loss=5.552383\n",
      "    e_l=2.784458 e_r=2.145210\n",
      "[-0.11693859  0.11061835 -0.9869595 ]\n",
      "[-0.08556209  0.07410432 -0.99357325]\n",
      "iter 147 lare=2.420176\n",
      "    ang_loss=6.735078\n",
      "    e_l=5.718203 e_r=6.024930\n",
      "[-0.05454803  0.19315962 -0.97964996]\n",
      "[-0.09953436  0.10466649 -0.9895139 ]\n",
      "iter 148 lare=0.758456\n",
      "    ang_loss=7.584558\n",
      "    e_l=8.363912 e_r=4.254686\n",
      "[ 0.1615579   0.09622493 -0.98216087]\n",
      "[ 0.02208698  0.05667621 -0.99814826]\n",
      "iter 149 lare=1.834765\n",
      "    ang_loss=7.856653\n",
      "    e_l=7.953544 e_r=4.988059\n",
      "[ 0.14301     0.06090825 -0.98784536]\n",
      "[ 0.00500857  0.07100333 -0.99746346]\n",
      "iter 150 lare=1.073689\n",
      "    ang_loss=5.935926\n",
      "    e_l=6.341988 e_r=8.432517\n",
      "[-0.0650282   0.20502716 -0.97659373]\n",
      "[-0.12960303  0.1155716  -0.9848078 ]\n",
      "iter 151 lare=0.480323\n",
      "    ang_loss=4.803226\n",
      "    e_l=2.027965 e_r=0.537412\n",
      "[-0.1572551   0.10676921 -0.98176944]\n",
      "[-0.12603892  0.12324771 -0.9843394 ]\n",
      "iter 152 lare=2.531008\n",
      "    ang_loss=6.763460\n",
      "    e_l=6.474871 e_r=6.969253\n",
      "[-0.12432911  0.25316808 -0.9594    ]\n",
      "[-0.08884489  0.148999   -0.984838  ]\n",
      "iter 153 lare=1.809139\n",
      "    ang_loss=6.459473\n",
      "    e_l=5.934353 e_r=6.866271\n",
      "[-0.20937385  0.14914212 -0.966395  ]\n",
      "[-0.10719159  0.14883834 -0.9830347 ]\n",
      "iter 154 lare=1.942249\n",
      "    ang_loss=6.083405\n",
      "    e_l=9.092281 e_r=3.869283\n",
      "[ 0.16939323  0.1275056  -0.9772658 ]\n",
      "[ 0.01164815  0.12307709 -0.99232876]\n",
      "iter 155 lare=1.309645\n",
      "    ang_loss=6.583864\n",
      "    e_l=5.788313 e_r=2.989109\n",
      "[ 0.05360327  0.12491453 -0.9907185 ]\n",
      "[-0.04684217  0.13527176 -0.9897007 ]\n",
      "iter 156 lare=0.647448\n",
      "    ang_loss=6.474481\n",
      "    e_l=7.474777 e_r=3.906153\n",
      "[ 0.09884957  0.11851805 -0.9880194 ]\n",
      "[-0.0310737   0.12880011 -0.9911837 ]\n",
      "iter 157 lare=0.947914\n",
      "    ang_loss=7.124772\n",
      "    e_l=15.928393 e_r=15.270659\n",
      "[ 0.09955632  0.08159429 -0.9916809 ]\n",
      "[-0.16372296  0.16587807 -0.9724603 ]\n",
      "iter 158 lare=1.336194\n",
      "    ang_loss=6.108982\n",
      "    e_l=6.295910 e_r=6.289211\n",
      "[-0.04872733  0.17860584 -0.98271346]\n",
      "[-0.15624359  0.15751915 -0.97507733]\n",
      "iter 159 lare=2.754151\n",
      "    ang_loss=7.810367\n",
      "    e_l=9.863503 e_r=9.546290\n",
      "[-0.00794242  0.02505196 -0.99965465]\n",
      "[-0.12563437  0.14897484 -0.98082745]\n",
      "iter 160 lare=2.310190\n",
      "    ang_loss=5.320863\n",
      "    e_l=6.252663 e_r=4.917490\n",
      "[ 0.09465414  0.21068172 -0.9729614 ]\n",
      "[ 0.00639311  0.14859979 -0.9888767 ]\n",
      "iter 161 lare=0.961353\n",
      "    ang_loss=4.754603\n",
      "    e_l=1.850866 e_r=2.773681\n",
      "[-0.0865148   0.10562743 -0.9906352 ]\n",
      "[-0.07391141  0.13525808 -0.98804975]\n",
      "iter 162 lare=1.552603\n",
      "    ang_loss=5.160707\n",
      "    e_l=3.871459 e_r=3.337888\n",
      "[-0.07013962  0.21482949 -0.9741298 ]\n",
      "[-0.08965579  0.15098296 -0.98446226]\n",
      "iter 163 lare=1.339450\n",
      "    ang_loss=6.247750\n",
      "    e_l=1.449154 e_r=2.365957\n",
      "[-0.18264873  0.14886038 -0.97184366]\n",
      "[-0.17552236  0.17298293 -0.9691589 ]\n",
      "iter 164 lare=0.611814\n",
      "    ang_loss=5.272384\n",
      "    e_l=8.394823 e_r=5.833580\n",
      "[ 0.12295816  0.07723314 -0.98940206]\n",
      "[-0.01361971  0.12987822 -0.9914364 ]\n",
      "iter 165 lare=1.007579\n",
      "    ang_loss=6.717706\n",
      "    e_l=5.248035 e_r=5.020164\n",
      "[-0.03100065  0.27022558 -0.9622979 ]\n",
      "[-0.03373996  0.18104912 -0.9828952 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 166 lare=1.958708\n",
      "    ang_loss=6.887131\n",
      "    e_l=5.680651 e_r=6.000838\n",
      "[ 0.01828005  0.27346715 -0.9617077 ]\n",
      "[ 0.0210939   0.17694022 -0.98399556]\n",
      "iter 167 lare=1.016818\n",
      "    ang_loss=6.630627\n",
      "    e_l=10.731941 e_r=8.184317\n",
      "[ 0.13678469  0.00139307 -0.9905999 ]\n",
      "[-0.00101932  0.1278466  -0.99179345]\n",
      "iter 168 lare=0.686326\n",
      "    ang_loss=4.652367\n",
      "    e_l=6.475173 e_r=4.760492\n",
      "[-0.23064832  0.09532799 -0.9683564 ]\n",
      "[-0.13952512  0.16151756 -0.9769569 ]\n",
      "iter 169 lare=1.266935\n",
      "    ang_loss=5.802367\n",
      "    e_l=3.169038 e_r=3.355380\n",
      "[-0.21084404  0.20864357 -0.9549936 ]\n",
      "[-0.17160629  0.1726417  -0.9699207 ]\n",
      "iter 170 lare=1.636910\n",
      "    ang_loss=5.634400\n",
      "    e_l=3.149270 e_r=0.973777\n",
      "[-0.12503314  0.10851333 -0.98620063]\n",
      "[-0.09585714  0.15499774 -0.9832534 ]\n",
      "iter 171 lare=2.041227\n",
      "    ang_loss=5.693233\n",
      "    e_l=9.295635 e_r=5.328331\n",
      "[ 0.15988015  0.24750882 -0.9556034 ]\n",
      "[ 0.01471905  0.18101396 -0.9833704 ]\n",
      "iter 172 lare=1.412807\n",
      "    ang_loss=6.280974\n",
      "    e_l=9.585193 e_r=8.184269\n",
      "[-0.14574727  0.01557718 -0.9891993 ]\n",
      "[-0.15778051  0.1812124  -0.9707045 ]\n",
      "iter 173 lare=0.760392\n",
      "    ang_loss=7.603923\n",
      "    e_l=8.849375 e_r=3.219540\n",
      "[ 0.16887566  0.15807883 -0.97287834]\n",
      "[ 0.01530565  0.16492619 -0.98618716]\n",
      "iter 174 lare=1.243554\n",
      "    ang_loss=6.225462\n",
      "    e_l=3.208393 e_r=2.212578\n",
      "[ 0.11596011  0.16508313 -0.9794391 ]\n",
      "[ 0.06151638  0.17786933 -0.98212934]\n",
      "iter 175 lare=0.974042\n",
      "    ang_loss=6.520666\n",
      "    e_l=5.873595 e_r=4.784545\n",
      "[-0.07478725  0.10785238 -0.99135   ]\n",
      "[-0.13539453  0.18835041 -0.9727243 ]\n",
      "iter 176 lare=1.491943\n",
      "    ang_loss=6.303738\n",
      "    e_l=2.850736 e_r=2.958698\n",
      "[ 0.04610858  0.2100274  -0.9766077 ]\n",
      "[ 0.0035442   0.18500836 -0.98273057]\n",
      "iter 177 lare=0.880158\n",
      "    ang_loss=5.949881\n",
      "    e_l=4.207985 e_r=0.761304\n",
      "[-0.20529827  0.11121804 -0.97235966]\n",
      "[-0.15944608  0.16856948 -0.9727083 ]\n",
      "iter 178 lare=1.108151\n",
      "    ang_loss=4.962638\n",
      "    e_l=7.917826 e_r=4.631723\n",
      "[ 0.06570298  0.25053754 -0.96587485]\n",
      "[-0.05922457  0.19327986 -0.9793546 ]\n",
      "iter 179 lare=1.252443\n",
      "    ang_loss=4.935685\n",
      "    e_l=5.564860 e_r=4.710188\n",
      "[ 0.06491064  0.25694004 -0.9642451 ]\n",
      "[ 0.00554566  0.18248984 -0.98319215]\n",
      "iter 180 lare=0.967754\n",
      "    ang_loss=4.965461\n",
      "    e_l=0.801374 e_r=0.712718\n",
      "[-0.08961489  0.21518973 -0.97245187]\n",
      "[-0.07568397  0.21607457 -0.97343916]\n",
      "iter 181 lare=1.560470\n",
      "    ang_loss=5.638598\n",
      "    e_l=5.588862 e_r=4.512624\n",
      "[-0.05105796  0.0710571  -0.9961647 ]\n",
      "[-0.00117024  0.15443632 -0.9880021 ]\n",
      "iter 182 lare=1.883915\n",
      "    ang_loss=5.346181\n",
      "    e_l=1.052763 e_r=2.706241\n",
      "[-0.02479122  0.21544708 -0.9762008 ]\n",
      "[-0.03601207  0.20114996 -0.9788982 ]\n",
      "iter 183 lare=1.086633\n",
      "    ang_loss=4.594243\n",
      "    e_l=5.710828 e_r=0.999559\n",
      "[-0.27628288  0.13239038 -0.95191425]\n",
      "[-0.20565628  0.20244676 -0.9574554 ]\n",
      "iter 184 lare=1.567100\n",
      "    ang_loss=4.823755\n",
      "    e_l=4.229525 e_r=4.427884\n",
      "[-0.01044975  0.27774945 -0.9605968 ]\n",
      "[-0.04560896  0.2146241  -0.97563124]\n",
      "iter 185 lare=1.917113\n",
      "    ang_loss=6.425296\n",
      "    e_l=5.054934 e_r=5.264698\n",
      "[ 0.0609353   0.07827274 -0.995068  ]\n",
      "[ 0.02236348  0.15720883 -0.9873122 ]\n",
      "iter 186 lare=2.230548\n",
      "    ang_loss=4.706597\n",
      "    e_l=4.599555 e_r=3.402084\n",
      "[-0.18649974  0.18550149 -0.9647835 ]\n",
      "[-0.10937491  0.20637861 -0.97234005]\n",
      "iter 187 lare=1.694988\n",
      "    ang_loss=5.775578\n",
      "    e_l=5.327154 e_r=3.919615\n",
      "[ 0.15904853  0.05403763 -0.98579085]\n",
      "[ 0.13485523  0.14361565 -0.9804023 ]\n",
      "iter 188 lare=2.526040\n",
      "    ang_loss=6.744291\n",
      "    e_l=0.470222 e_r=2.271847\n",
      "[-0.03162676  0.18303241 -0.98259807]\n",
      "[-0.02816926  0.19036739 -0.9813087 ]\n",
      "iter 189 lare=0.670232\n",
      "    ang_loss=4.378897\n",
      "    e_l=7.385011 e_r=6.689088\n",
      "[ 0.11395319  0.0240194  -0.9931958 ]\n",
      "[ 0.04759656  0.13436285 -0.9897885 ]\n",
      "iter 190 lare=2.806370\n",
      "    ang_loss=6.441304\n",
      "    e_l=2.494655 e_r=1.554945\n",
      "[-0.01035973  0.22030288 -0.97537655]\n",
      "[-0.05214282  0.23185664 -0.97135144]\n",
      "iter 191 lare=1.235822\n",
      "    ang_loss=5.541641\n",
      "    e_l=6.032994 e_r=2.513571\n",
      "[-0.09875447  0.09618375 -0.9904526 ]\n",
      "[-0.03153908  0.17689165 -0.98372483]\n",
      "iter 192 lare=2.019889\n",
      "    ang_loss=5.691398\n",
      "    e_l=3.941636 e_r=4.266363\n",
      "[ 0.10043152  0.24744888 -0.9636818 ]\n",
      "[ 0.03656355  0.22405088 -0.9738913 ]\n",
      "iter 193 lare=0.962142\n",
      "    ang_loss=5.430202\n",
      "    e_l=5.167860 e_r=6.491385\n",
      "[ 0.16294691  0.19954303 -0.96624583]\n",
      "[ 0.07681958  0.22576974 -0.97114706]\n",
      "iter 194 lare=0.734914\n",
      "    ang_loss=6.730350\n",
      "    e_l=11.894974 e_r=5.599862\n",
      "[-0.25382367  0.13678308 -0.9575302 ]\n",
      "[-0.08164198  0.25190762 -0.9643014 ]\n",
      "iter 195 lare=1.179969\n",
      "    ang_loss=7.023388\n",
      "    e_l=10.607973 e_r=8.514422\n",
      "[ 0.11079129  0.01355417 -0.99375135]\n",
      "[ 0.08758242  0.19617328 -0.9766501 ]\n",
      "iter 196 lare=1.232967\n",
      "    ang_loss=7.449682\n",
      "    e_l=10.874549 e_r=5.435271\n",
      "[-0.01455216  0.03992203 -0.9990969 ]\n",
      "[ 0.06158309  0.21183795 -0.97536266]\n",
      "iter 197 lare=0.763995\n",
      "    ang_loss=7.639951\n",
      "    e_l=14.630666 e_r=8.515206\n",
      "[-0.2418348   0.13166112 -0.9613435 ]\n",
      "[-0.00461074  0.22329745 -0.97473943]\n",
      "iter 198 lare=1.429185\n",
      "    ang_loss=8.771424\n",
      "    e_l=16.246994 e_r=8.144662\n",
      "[-0.22181597  0.05844208 -0.9733357 ]\n",
      "[-0.02019109  0.25635633 -0.9663715 ]\n",
      "iter 199 lare=0.763959\n",
      "    ang_loss=7.639590\n",
      "    e_l=8.627985 e_r=5.036489\n",
      "[-0.15045358  0.2593767  -0.9539851 ]\n",
      "[-0.00114919  0.2764702  -0.9610217 ]\n",
      "iter 200 lare=0.812660\n",
      "    ang_loss=6.772406\n",
      "    e_l=11.724857 e_r=3.299899\n",
      "[-0.02528441  0.02306048 -0.9994143 ]\n",
      "[ 0.06502692  0.20487165 -0.97662646]\n",
      "iter 201 lare=1.092661\n",
      "    ang_loss=6.238837\n",
      "    e_l=5.659184 e_r=5.445141\n",
      "[-0.15466486  0.23433337 -0.9597743 ]\n",
      "[-0.05793164  0.2531939  -0.9656794 ]\n",
      "iter 202 lare=1.440912\n",
      "    ang_loss=5.588255\n",
      "    e_l=9.514278 e_r=2.154950\n",
      "[-0.1565515   0.14098585 -0.9775555 ]\n",
      "[ 0.00210961  0.18913886 -0.9819481 ]\n",
      "iter 203 lare=0.832148\n",
      "    ang_loss=5.595855\n",
      "    e_l=5.728887 e_r=4.559519\n",
      "[-0.14990807  0.2325312  -0.96096665]\n",
      "[-0.05054606  0.23882274 -0.9697468 ]\n",
      "iter 204 lare=1.582818\n",
      "    ang_loss=5.800535\n",
      "    e_l=1.380126 e_r=4.849170\n",
      "[ 0.11167365  0.16359264 -0.980187  ]\n",
      "[ 0.11351459  0.18719271 -0.9757424 ]\n",
      "iter 205 lare=1.734937\n",
      "    ang_loss=5.987339\n",
      "    e_l=4.060521 e_r=3.174655\n",
      "[ 0.17083724  0.09858158 -0.98035526]\n",
      "[ 0.16892347  0.16880067 -0.9710671 ]\n",
      "iter 206 lare=1.035031\n",
      "    ang_loss=4.297338\n",
      "    e_l=6.809419 e_r=3.950667\n",
      "[-0.01501668  0.10397884 -0.9944662 ]\n",
      "[ 0.03305415  0.21116227 -0.97689193]\n",
      "iter 207 lare=2.180885\n",
      "    ang_loss=6.436624\n",
      "    e_l=6.530027 e_r=8.556851\n",
      "[ 0.11756233  0.2475541  -0.9617152 ]\n",
      "[ 0.01422951  0.20288388 -0.9790994 ]\n",
      "iter 208 lare=1.813289\n",
      "    ang_loss=5.656553\n",
      "    e_l=7.389367 e_r=6.025646\n",
      "[-0.23373103  0.16538814 -0.95813185]\n",
      "[-0.11885899  0.22306201 -0.96753097]\n",
      "iter 209 lare=1.906254\n",
      "    ang_loss=5.220693\n",
      "    e_l=7.818286 e_r=8.345531\n",
      "[-0.02632588  0.05460548 -0.99816096]\n",
      "[ 0.00814604  0.18560366 -0.982591  ]\n",
      "iter 210 lare=0.856554\n",
      "    ang_loss=5.242625\n",
      "    e_l=6.405329 e_r=4.374033\n",
      "[ 0.04947992  0.12995993 -0.99028397]\n",
      "[-0.04864269  0.18275997 -0.98195356]\n",
      "iter 211 lare=1.606259\n",
      "    ang_loss=4.688344\n",
      "    e_l=7.270734 e_r=5.301786\n",
      "[ 0.13013296  0.15649271 -0.9790687 ]\n",
      "[ 0.01291865  0.20488927 -0.97869986]\n",
      "iter 212 lare=1.526051\n",
      "    ang_loss=3.776287\n",
      "    e_l=7.286988 e_r=5.119368\n",
      "[ 0.12614359  0.25941432 -0.95749265]\n",
      "[ 0.02254732  0.18982744 -0.98155856]\n",
      "iter 213 lare=1.097178\n",
      "    ang_loss=5.974495\n",
      "    e_l=2.661460 e_r=1.842282\n",
      "[ 0.12962566  0.18408303 -0.9743258 ]\n",
      "[ 0.17510578  0.18895681 -0.966247  ]\n",
      "iter 214 lare=1.132466\n",
      "    ang_loss=5.752685\n",
      "    e_l=13.253382 e_r=8.899891\n",
      "[-0.21410327 -0.00300341 -0.97680646]\n",
      "[-0.10247923  0.19899684 -0.9746273 ]\n",
      "iter 215 lare=1.517605\n",
      "    ang_loss=5.698744\n",
      "    e_l=6.895175 e_r=4.256665\n",
      "[ 0.0691078   0.06093307 -0.9957467 ]\n",
      "[ 0.11484114  0.17083766 -0.97858363]\n",
      "iter 216 lare=0.859888\n",
      "    ang_loss=5.903186\n",
      "    e_l=11.812078 e_r=7.499989\n",
      "[ 0.06318048  0.00616877 -0.9979831 ]\n",
      "[ 0.00178894  0.20171627 -0.9794423 ]\n",
      "iter 217 lare=0.961038\n",
      "    ang_loss=5.688507\n",
      "    e_l=7.663035 e_r=2.744808\n",
      "[-0.06163039  0.0971552  -0.99335927]\n",
      "[-0.04143993  0.22766593 -0.97285706]\n",
      "iter 218 lare=1.831722\n",
      "    ang_loss=5.966469\n",
      "    e_l=4.558316 e_r=2.764987\n",
      "[ 0.02633796  0.27011293 -0.9624684 ]\n",
      "[-0.05319161  0.27016446 -0.96134377]\n",
      "iter 219 lare=1.386823\n",
      "    ang_loss=7.143845\n",
      "    e_l=3.848478 e_r=5.758507\n",
      "[ 0.00811347  0.27674446 -0.96090937]\n",
      "[ 0.01394518  0.21185386 -0.97720194]\n",
      "iter 220 lare=1.698953\n",
      "    ang_loss=7.114868\n",
      "    e_l=10.815068 e_r=11.531807\n",
      "[-0.28399897  0.05860301 -0.9570321 ]\n",
      "[-0.16784956  0.20688353 -0.96385986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 221 lare=2.171681\n",
      "    ang_loss=8.511777\n",
      "    e_l=14.678856 e_r=11.269754\n",
      "[-0.23494224 -0.05078036 -0.970682  ]\n",
      "[-0.28775075  0.19694912 -0.93723553]\n",
      "iter 222 lare=0.717643\n",
      "    ang_loss=7.176428\n",
      "    e_l=12.439296 e_r=7.885506\n",
      "[-0.1457527  -0.00461933 -0.9893103 ]\n",
      "[-0.2711655   0.16715983 -0.9479066 ]\n",
      "iter 223 lare=1.416815\n",
      "    ang_loss=9.186803\n",
      "    e_l=14.717042 e_r=11.111169\n",
      "[ 0.12072912  0.16074306 -0.97958475]\n",
      "[-0.13302945  0.12595691 -0.9830758 ]\n",
      "iter 224 lare=1.470958\n",
      "    ang_loss=7.123386\n",
      "    e_l=13.423204 e_r=10.116140\n",
      "[ 0.05191118  0.16126241 -0.9855454 ]\n",
      "[-0.18105656  0.17004359 -0.9686608 ]\n",
      "iter 225 lare=1.145902\n",
      "    ang_loss=7.975774\n",
      "    e_l=11.332891 e_r=5.855246\n",
      "[ 0.06441449  0.16104493 -0.98484284]\n",
      "[-0.1320624   0.14157979 -0.9810784 ]\n",
      "iter 226 lare=1.232498\n",
      "    ang_loss=6.433372\n",
      "    e_l=12.010533 e_r=6.003842\n",
      "[ 0.12941174  0.00875938 -0.9915523 ]\n",
      "[-0.07051908  0.07037909 -0.99502456]\n",
      "iter 227 lare=1.827538\n",
      "    ang_loss=5.703510\n",
      "    e_l=9.361452 e_r=4.555350\n",
      "[ 0.16281457  0.1561045  -0.9742294 ]\n",
      "[ 0.03214274  0.061159   -0.99761033]\n",
      "iter 228 lare=1.332285\n",
      "    ang_loss=6.264826\n",
      "    e_l=10.329711 e_r=6.312953\n",
      "[ 0.03104879  0.1276463  -0.9913337 ]\n",
      "[-0.07837655 -0.01522414 -0.99680763]\n",
      "iter 229 lare=1.302699\n",
      "    ang_loss=5.424410\n",
      "    e_l=1.369308 e_r=3.263448\n",
      "[-0.00232309  0.00483418 -0.9999857 ]\n",
      "[-0.02349111  0.01593305 -0.99959713]\n",
      "iter 230 lare=0.753533\n",
      "    ang_loss=5.771824\n",
      "    e_l=6.427973 e_r=4.635824\n",
      "[ 0.02289043  0.16019821 -0.9868195 ]\n",
      "[ 0.03521162  0.04932492 -0.9981619 ]\n",
      "iter 231 lare=1.184664\n",
      "    ang_loss=6.974926\n",
      "    e_l=8.776127 e_r=5.370858\n",
      "[ 0.10048119  0.19287425 -0.97606516]\n",
      "[ 0.0200528   0.06450557 -0.99771583]\n",
      "iter 232 lare=1.129338\n",
      "    ang_loss=7.204746\n",
      "    e_l=10.181938 e_r=4.327440\n",
      "[ 0.09387539  0.17207415 -0.98060083]\n",
      "[ 0.02623882  0.00909874 -0.9996142 ]\n",
      "iter 233 lare=2.297330\n",
      "    ang_loss=5.563931\n",
      "    e_l=5.182739 e_r=5.366515\n",
      "[-0.02443422  0.0892254  -0.99571174]\n",
      "[-0.05989541  0.00607985 -0.9981862 ]\n",
      "iter 234 lare=1.002582\n",
      "    ang_loss=4.192014\n",
      "    e_l=2.100029 e_r=2.048417\n",
      "[-0.09155028  0.03413929 -0.9952151 ]\n",
      "[-0.05827004  0.04937144 -0.9970792 ]\n",
      "iter 235 lare=1.377947\n",
      "    ang_loss=5.520613\n",
      "    e_l=10.486873 e_r=9.387429\n",
      "[ 0.11017931  0.23982914 -0.9645427 ]\n",
      "[-0.03012847  0.12586011 -0.9915904 ]\n",
      "iter 236 lare=0.881912\n",
      "    ang_loss=6.041010\n",
      "    e_l=9.455836 e_r=8.654510\n",
      "[ 0.04611765  0.23568392 -0.97073495]\n",
      "[ 0.15170579  0.10962083 -0.9823282 ]\n",
      "iter 237 lare=2.637533\n",
      "    ang_loss=6.807885\n",
      "    e_l=6.237342 e_r=6.357427\n",
      "[ 0.1092806   0.21682633 -0.97007436]\n",
      "[ 0.10863567  0.10951219 -0.98803097]\n",
      "iter 238 lare=3.687192\n",
      "    ang_loss=5.768147\n",
      "    e_l=6.098118 e_r=7.500067\n",
      "[-0.19772467  0.20005839 -0.95962584]\n",
      "[-0.10187366  0.15964118 -0.9819045 ]\n",
      "iter 239 lare=1.720567\n",
      "    ang_loss=4.598499\n",
      "    e_l=3.850614 e_r=3.527588\n",
      "[ 0.100428    0.28003058 -0.95472366]\n",
      "[ 0.04564843  0.24373929 -0.96876585]\n",
      "iter 240 lare=0.615485\n",
      "    ang_loss=6.010412\n",
      "    e_l=2.407941 e_r=2.182654\n",
      "[-0.24711883  0.25970036 -0.9335353 ]\n",
      "[-0.27494943  0.22821592 -0.9339808 ]\n",
      "iter 241 lare=1.073636\n",
      "    ang_loss=8.379137\n",
      "    e_l=3.611240 e_r=5.028197\n",
      "[-0.17772788  0.12960553 -0.97550774]\n",
      "[-0.19032958  0.19009878 -0.9631391 ]\n",
      "iter 242 lare=0.906795\n",
      "    ang_loss=9.067953\n",
      "    e_l=13.047993 e_r=7.931177\n",
      "[ 0.09103434  0.15704313 -0.9833872 ]\n",
      "[-0.0853802   0.29660648 -0.9511756 ]\n",
      "iter 243 lare=1.690327\n",
      "    ang_loss=10.001591\n",
      "    e_l=11.925124 e_r=7.767787\n",
      "[-0.05454803  0.19315962 -0.97964996]\n",
      "[-0.2519748   0.24183585 -0.9370294 ]\n",
      "iter 244 lare=1.060949\n",
      "    ang_loss=9.698504\n",
      "    e_l=12.472088 e_r=6.061909\n",
      "[-0.0642522   0.12880819 -0.9895859 ]\n",
      "[-0.21764156  0.2733763  -0.9369619 ]\n",
      "iter 245 lare=1.017724\n",
      "    ang_loss=10.177243\n",
      "    e_l=12.648382 e_r=7.423410\n",
      "[ 1.8637333e-04  2.0173751e-01 -9.7943968e-01]\n",
      "[-0.210633    0.25482613 -0.94376767]\n",
      "iter 246 lare=1.045137\n",
      "    ang_loss=10.451374\n",
      "    e_l=14.637045 e_r=8.038856\n",
      "[-0.14522055  0.05904676 -0.98763585]\n",
      "[-0.33822277  0.20978844 -0.91738445]\n",
      "iter 247 lare=1.129567\n",
      "    ang_loss=9.291214\n",
      "    e_l=11.256763 e_r=6.231902\n",
      "[-0.26268563  0.01662575 -0.9647383 ]\n",
      "[-0.36031166  0.17944863 -0.91540897]\n",
      "iter 248 lare=0.846341\n",
      "    ang_loss=8.463406\n",
      "    e_l=15.369154 e_r=6.552660\n",
      "[ 0.18049864  0.12499534 -0.9756006 ]\n",
      "[-0.06083282  0.24004906 -0.9688529 ]\n",
      "iter 249 lare=0.690284\n",
      "    ang_loss=6.902836\n",
      "    e_l=7.204729 e_r=1.860568\n",
      "[-0.14593826  0.18135242 -0.9725294 ]\n",
      "[-0.26586896  0.20355085 -0.9422743 ]\n",
      "iter 250 lare=1.738190\n",
      "    ang_loss=8.432875\n",
      "    e_l=14.510268 e_r=6.208388\n",
      "[ 0.16294691  0.19954303 -0.96624583]\n",
      "[-0.08903812  0.18716264 -0.97828543]\n",
      "iter 251 lare=0.930693\n",
      "    ang_loss=7.260882\n",
      "    e_l=14.478189 e_r=4.816783\n",
      "[ 0.05594341  0.02481747 -0.9981255 ]\n",
      "[-0.13765499  0.18423058 -0.9731959 ]\n",
      "iter 252 lare=1.860102\n",
      "    ang_loss=6.989347\n",
      "    e_l=5.794439 e_r=4.779589\n",
      "[-0.01264612  0.20788798 -0.978071  ]\n",
      "[-0.10512518  0.16712369 -0.98031545]\n",
      "iter 253 lare=1.909671\n",
      "    ang_loss=5.880672\n",
      "    e_l=5.791530 e_r=3.799523\n",
      "[-0.00794242  0.02505196 -0.99965465]\n",
      "[-0.04382954  0.1191835  -0.9919043 ]\n",
      "iter 254 lare=1.447506\n",
      "    ang_loss=4.857402\n",
      "    e_l=3.413173 e_r=0.819483\n",
      "[-0.08444884  0.20564663 -0.9749759 ]\n",
      "[-0.11723407  0.2531586  -0.96029526]\n",
      "iter 255 lare=2.565719\n",
      "    ang_loss=6.029386\n",
      "    e_l=10.991661 e_r=8.611533\n",
      "[ 0.18421325  0.08394878 -0.9792948 ]\n",
      "[ 0.04179091  0.2120021  -0.9763752 ]\n",
      "iter 256 lare=1.183299\n",
      "    ang_loss=7.141368\n",
      "    e_l=7.336897 e_r=4.614479\n",
      "[-0.01872708  0.2553604  -0.9666646 ]\n",
      "[ 0.09909865  0.20591028 -0.97354025]\n",
      "iter 257 lare=0.953154\n",
      "    ang_loss=8.147305\n",
      "    e_l=13.749851 e_r=6.733389\n",
      "[-0.17517667  0.06338421 -0.98249465]\n",
      "[ 0.03510852  0.17781243 -0.98343784]\n",
      "iter 258 lare=0.949021\n",
      "    ang_loss=7.259993\n",
      "    e_l=5.237009 e_r=2.058330\n",
      "[ 0.09024245  0.17888923 -0.9797219 ]\n",
      "[ 0.17419304  0.21029902 -0.9619932 ]\n",
      "iter 259 lare=0.865134\n",
      "    ang_loss=8.651340\n",
      "    e_l=9.271269 e_r=1.319231\n",
      "[ 0.01698345  0.20899975 -0.97776824]\n",
      "[ 0.17425945  0.23877971 -0.9553104 ]\n",
      "iter 260 lare=1.857298\n",
      "    ang_loss=8.432656\n",
      "    e_l=6.012587 e_r=7.570641\n",
      "[ 0.05728036  0.20631294 -0.9768081 ]\n",
      "[ 0.12803864  0.12915753 -0.9833231 ]\n",
      "iter 261 lare=1.158735\n",
      "    ang_loss=8.453489\n",
      "    e_l=14.247006 e_r=3.597225\n",
      "[ 0.00263237  0.14672491 -0.9891739 ]\n",
      "[ 0.23411651  0.22455154 -0.9459208 ]\n",
      "iter 262 lare=0.906160\n",
      "    ang_loss=9.061604\n",
      "    e_l=8.929664 e_r=6.272355\n",
      "[ 0.15687312  0.03878388 -0.986857  ]\n",
      "[ 0.23040953  0.17286728 -0.95761603]\n",
      "iter 263 lare=1.415870\n",
      "    ang_loss=8.105050\n",
      "    e_l=5.182247 e_r=1.930467\n",
      "[ 0.09957826  0.21464172 -0.97160345]\n",
      "[ 0.1888911   0.20663552 -0.9600114 ]\n",
      "iter 264 lare=0.915215\n",
      "    ang_loss=9.152145\n",
      "    e_l=11.109184 e_r=5.214511\n",
      "[-0.01471672  0.19934401 -0.9798191 ]\n",
      "[ 0.17786777  0.20754914 -0.96191806]\n",
      "iter 265 lare=0.897412\n",
      "    ang_loss=8.974119\n",
      "    e_l=12.618667 e_r=6.818573\n",
      "[ 6.0245901e-02  6.8840443e-04 -9.9818337e-01]\n",
      "[ 0.20883353  0.15919201 -0.9649075 ]\n",
      "iter 266 lare=1.644063\n",
      "    ang_loss=8.041724\n",
      "    e_l=10.987057 e_r=6.632617\n",
      "[-0.12414588  0.21509272 -0.9686708 ]\n",
      "[ 0.05502464  0.15015613 -0.98712987]\n",
      "iter 267 lare=0.912692\n",
      "    ang_loss=9.126916\n",
      "    e_l=5.529070 e_r=2.185342\n",
      "[ 0.07699803  0.14002594 -0.98714954]\n",
      "[ 0.16546541  0.17474505 -0.9706109 ]\n",
      "iter 268 lare=0.687959\n",
      "    ang_loss=6.879585\n",
      "    e_l=8.915660 e_r=5.028976\n",
      "[-0.0652791   0.17268102 -0.9828123 ]\n",
      "[ 0.08746255  0.14393534 -0.9857143 ]\n",
      "iter 269 lare=1.599613\n",
      "    ang_loss=7.077118\n",
      "    e_l=14.399051 e_r=7.254472\n",
      "[-0.25832817  0.19628577 -0.9459062 ]\n",
      "[-0.01271681  0.16637221 -0.9859811 ]\n",
      "iter 270 lare=0.799628\n",
      "    ang_loss=6.975405\n",
      "    e_l=11.593434 e_r=7.338422\n",
      "[-0.20233765  0.22308394 -0.95356864]\n",
      "[-0.01216299  0.16346353 -0.9864745 ]\n",
      "iter 271 lare=1.656513\n",
      "    ang_loss=5.610890\n",
      "    e_l=4.908718 e_r=3.286046\n",
      "[ 0.18608879  0.10615608 -0.9767814 ]\n",
      "[ 0.11013384  0.14520177 -0.9832533 ]\n",
      "iter 272 lare=0.777231\n",
      "    ang_loss=5.802792\n",
      "    e_l=7.540903 e_r=2.559179\n",
      "[-0.15194608  0.2259497  -0.9622158 ]\n",
      "[-0.02839528  0.18554987 -0.9822245 ]\n",
      "iter 273 lare=1.635432\n",
      "    ang_loss=4.621745\n",
      "    e_l=4.776227 e_r=4.135833\n",
      "[-0.03162676  0.18303241 -0.98259807]\n",
      "[-0.03270199  0.10054285 -0.9943951 ]\n",
      "iter 274 lare=1.274673\n",
      "    ang_loss=4.913073\n",
      "    e_l=7.695390 e_r=6.508521\n",
      "[-0.15764207  0.19875039 -0.9672887 ]\n",
      "[-0.19291666  0.0697661  -0.97873175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 275 lare=1.154057\n",
      "    ang_loss=5.526562\n",
      "    e_l=6.175427 e_r=4.216354\n",
      "[ 0.06203414  0.10044333 -0.99300706]\n",
      "[-0.04444153  0.11681698 -0.9921587 ]\n",
      "iter 276 lare=1.821018\n",
      "    ang_loss=5.502888\n",
      "    e_l=5.165926 e_r=4.733503\n",
      "[-0.15251681  0.04225494 -0.9873972 ]\n",
      "[-0.0970755   0.11330483 -0.9888065 ]\n",
      "iter 277 lare=1.797343\n",
      "    ang_loss=6.581379\n",
      "    e_l=9.869322 e_r=11.077342\n",
      "[-0.23860274  0.23639861 -0.9419047 ]\n",
      "[-0.15728804  0.09057542 -0.98339033]\n",
      "iter 278 lare=1.976363\n",
      "    ang_loss=5.898429\n",
      "    e_l=8.557494 e_r=3.358996\n",
      "[ 5.7653338e-04  1.2292657e-02 -9.9992436e-01]\n",
      "[-0.14253609  0.05293291 -0.9883733 ]\n",
      "iter 279 lare=1.488332\n",
      "    ang_loss=6.818387\n",
      "    e_l=3.827866 e_r=1.826492\n",
      "[-0.09177844  0.08286486 -0.99232566]\n",
      "[-0.15213789  0.10964793 -0.9822584 ]\n",
      "iter 280 lare=0.704667\n",
      "    ang_loss=7.046669\n",
      "    e_l=11.400902 e_r=6.738076\n",
      "[ 0.06045415  0.23718694 -0.96958125]\n",
      "[-0.11566941  0.14620067 -0.9824693 ]\n",
      "iter 281 lare=1.153880\n",
      "    ang_loss=6.280976\n",
      "    e_l=15.898973 e_r=5.324173\n",
      "[ 0.14880618  0.14866108 -0.9776281 ]\n",
      "[-0.12230312  0.09480193 -0.98795474]\n",
      "iter 282 lare=0.940754\n",
      "    ang_loss=6.815066\n",
      "    e_l=16.800980 e_r=10.563748\n",
      "[ 0.1441315   0.10898132 -0.98353916]\n",
      "[-0.14422274  0.15570135 -0.9772189 ]\n",
      "iter 283 lare=0.677369\n",
      "    ang_loss=6.773689\n",
      "    e_l=11.235330 e_r=3.967731\n",
      "[ 0.05936977  0.09314138 -0.9938813 ]\n",
      "[-0.13079283  0.13809308 -0.9817452 ]\n",
      "iter 284 lare=1.983094\n",
      "    ang_loss=7.034041\n",
      "    e_l=10.248240 e_r=5.093622\n",
      "[ 0.04896661  0.07877754 -0.995689  ]\n",
      "[-0.1192304   0.13763201 -0.98328114]\n",
      "iter 285 lare=1.716588\n",
      "    ang_loss=7.315155\n",
      "    e_l=7.851305 e_r=1.001710\n",
      "[ 0.09211453  0.21046098 -0.9732529 ]\n",
      "[-0.04110694  0.1802947  -0.9827533 ]\n",
      "iter 286 lare=1.585599\n",
      "    ang_loss=6.838480\n",
      "    e_l=12.611850 e_r=3.636473\n",
      "[ 0.17234035  0.1138681  -0.97843397]\n",
      "[-0.03967832  0.17103979 -0.9844648 ]\n",
      "iter 287 lare=1.095892\n",
      "    ang_loss=5.706770\n",
      "    e_l=9.682289 e_r=2.818973\n",
      "[ 0.1532148   0.20095249 -0.9675451 ]\n",
      "[-0.01387385  0.18278295 -0.9830555 ]\n",
      "iter 288 lare=1.736516\n",
      "    ang_loss=6.770843\n",
      "    e_l=8.165824 e_r=8.723617\n",
      "[-0.17551228  0.23666286 -0.9556078 ]\n",
      "[-0.20269659  0.09813824 -0.9743116 ]\n",
      "iter 289 lare=1.537154\n",
      "    ang_loss=6.194856\n",
      "    e_l=6.925377 e_r=9.896681\n",
      "[-0.24301541  0.25337544 -0.93634635]\n",
      "[-0.2148239   0.13987258 -0.96658486]\n",
      "iter 290 lare=2.606723\n",
      "    ang_loss=6.627817\n",
      "    e_l=8.192133 e_r=4.309708\n",
      "[ 0.14715761  0.20678225 -0.9672569 ]\n",
      "[ 0.00600826  0.19017582 -0.98173165]\n",
      "iter 291 lare=1.764173\n",
      "    ang_loss=8.078671\n",
      "    e_l=11.160485 e_r=6.510147\n",
      "[ 0.15757519  0.21327232 -0.9642018 ]\n",
      "[-0.036325    0.22487448 -0.9737104 ]\n",
      "iter 292 lare=1.326752\n",
      "    ang_loss=4.590983\n",
      "    e_l=7.755169 e_r=3.055757\n",
      "[ 0.09884957  0.11851805 -0.9880194 ]\n",
      "[-0.00480198  0.20490915 -0.97876924]\n",
      "iter 293 lare=0.688267\n",
      "    ang_loss=6.309674\n",
      "    e_l=5.896145 e_r=5.216315\n",
      "[-0.17708552  0.10879099 -0.97816426]\n",
      "[-0.15495706  0.2084651  -0.96567625]\n",
      "iter 294 lare=1.746688\n",
      "    ang_loss=5.872427\n",
      "    e_l=4.602960 e_r=0.106531\n",
      "[ 0.02633796  0.27011293 -0.9624684 ]\n",
      "[-0.04857777  0.24192418 -0.96907836]\n",
      "iter 295 lare=1.101382\n",
      "    ang_loss=6.635754\n",
      "    e_l=4.053184 e_r=4.541570\n",
      "[-0.2312153   0.23094183 -0.9450955 ]\n",
      "[-0.16256368  0.24393722 -0.9560689 ]\n",
      "iter 296 lare=1.750860\n",
      "    ang_loss=6.426491\n",
      "    e_l=7.924888 e_r=8.499717\n",
      "[-0.06538506  0.06178055 -0.9959458 ]\n",
      "[-0.16666715  0.15322831 -0.97403455]\n",
      "iter 297 lare=1.136966\n",
      "    ang_loss=5.161889\n",
      "    e_l=7.019816 e_r=2.861839\n",
      "[ 0.02560024  0.11292406 -0.99327385]\n",
      "[-0.09306671  0.14206862 -0.98547196]\n",
      "iter 298 lare=1.595321\n",
      "    ang_loss=5.964478\n",
      "    e_l=1.054434 e_r=6.196250\n",
      "[-0.04549669  0.22651967 -0.9729435 ]\n",
      "[-0.03200047  0.21443354 -0.9762143 ]\n",
      "iter 299 lare=1.636575\n",
      "    ang_loss=4.472442\n",
      "    e_l=5.535659 e_r=1.626904\n",
      "[ 0.14902945  0.13358818 -0.9797676 ]\n",
      "[ 0.0737739   0.19409867 -0.978204  ]\n",
      "iter 300 lare=2.619542\n",
      "    ang_loss=4.680623\n",
      "    e_l=1.971991 e_r=3.074916\n",
      "[-0.16730717  0.14707272 -0.97487336]\n",
      "[-0.14231718  0.17073858 -0.97498417]\n",
      "iter 301 lare=1.669618\n",
      "    ang_loss=5.334660\n",
      "    e_l=5.065658 e_r=4.118656\n",
      "[-0.1367922   0.22678332 -0.9642911 ]\n",
      "[-0.15081164  0.14068435 -0.97850066]\n",
      "iter 302 lare=2.319889\n",
      "    ang_loss=5.383666\n",
      "    e_l=8.112514 e_r=3.048959\n",
      "[ 0.11789584  0.06608575 -0.9908246 ]\n",
      "[-0.02038701  0.09563291 -0.99520785]\n",
      "iter 303 lare=1.115004\n",
      "    ang_loss=4.214245\n",
      "    e_l=3.574346 e_r=1.954346\n",
      "[-0.10327432  0.13920718 -0.9848634 ]\n",
      "[-0.11653947  0.07848321 -0.99008024]\n",
      "iter 304 lare=0.457956\n",
      "    ang_loss=4.275923\n",
      "    e_l=0.360452 e_r=1.416374\n",
      "[-0.0865148   0.10562743 -0.9906352 ]\n",
      "[-0.08142545  0.10934782 -0.99066293]\n",
      "iter 305 lare=2.084030\n",
      "    ang_loss=5.081760\n",
      "    e_l=5.136981 e_r=3.299484\n",
      "[ 0.04781597  0.18096417 -0.9823267 ]\n",
      "[-0.03794302  0.15536076 -0.9871289 ]\n",
      "iter 306 lare=1.818997\n",
      "    ang_loss=4.888064\n",
      "    e_l=12.841880 e_r=6.824639\n",
      "[ 0.14678337  0.10806771 -0.98324776]\n",
      "[-0.07500449  0.13661896 -0.98778003]\n",
      "iter 307 lare=0.717758\n",
      "    ang_loss=3.935538\n",
      "    e_l=6.019104 e_r=5.501853\n",
      "[-0.01718224  0.05271833 -0.99846166]\n",
      "[-0.05574597  0.14973006 -0.9871542 ]\n",
      "iter 308 lare=0.947946\n",
      "    ang_loss=5.287137\n",
      "    e_l=3.069372 e_r=1.238752\n",
      "[-0.17772788  0.12960553 -0.97550774]\n",
      "[-0.17068888  0.07694294 -0.98231614]\n",
      "iter 309 lare=2.325413\n",
      "    ang_loss=6.825912\n",
      "    e_l=16.024403 e_r=16.204449\n",
      "[ 0.16517271  0.06765378 -0.9839416 ]\n",
      "[-0.09939457  0.15548697 -0.9828248 ]\n",
      "iter 310 lare=0.988717\n",
      "    ang_loss=4.907125\n",
      "    e_l=6.361651 e_r=6.131717\n",
      "[-0.04601603  0.21753056 -0.97496825]\n",
      "[-0.08856682  0.1160411  -0.9892879 ]\n",
      "iter 311 lare=1.491378\n",
      "    ang_loss=5.439042\n",
      "    e_l=3.992676 e_r=2.732873\n",
      "[ 0.02021275  0.16493014 -0.9860982 ]\n",
      "[-0.03644044  0.12474065 -0.99152   ]\n",
      "iter 312 lare=0.870121\n",
      "    ang_loss=3.805586\n",
      "    e_l=8.729379 e_r=7.040214\n",
      "[ 0.1092806   0.21682633 -0.97007436]\n",
      "[ 0.00798873  0.10583967 -0.99435097]\n",
      "iter 313 lare=2.215565\n",
      "    ang_loss=5.646292\n",
      "    e_l=13.734541 e_r=8.153841\n",
      "[-0.03952368  0.27638245 -0.96023476]\n",
      "[-0.15831831  0.07030427 -0.98488206]\n",
      "iter 314 lare=0.908513\n",
      "    ang_loss=4.833191\n",
      "    e_l=11.870295 e_r=10.752023\n",
      "[-0.12992753  0.24567294 -0.9606059 ]\n",
      "[-0.13261989  0.0410306  -0.9903173 ]\n",
      "iter 315 lare=0.677836\n",
      "    ang_loss=3.900222\n",
      "    e_l=4.450782 e_r=2.501315\n",
      "[ 0.16075522  0.18351431 -0.96978366]\n",
      "[ 0.10708522  0.12970068 -0.9857538 ]\n",
      "iter 316 lare=0.686208\n",
      "    ang_loss=4.352309\n",
      "    e_l=1.970402 e_r=1.008718\n",
      "[ 0.13368693  0.11606523 -0.98420364]\n",
      "[ 0.10860867  0.13959728 -0.9842341 ]\n",
      "iter 317 lare=1.077795\n",
      "    ang_loss=5.011010\n",
      "    e_l=0.505904 e_r=1.372306\n",
      "[-0.23013555  0.09437263 -0.9685719 ]\n",
      "[-0.23808862  0.09749845 -0.9663373 ]\n",
      "iter 318 lare=1.027683\n",
      "    ang_loss=4.706358\n",
      "    e_l=9.624226 e_r=5.954304\n",
      "[ 0.00203357  0.00822864 -0.9999641 ]\n",
      "[-0.10005445  0.14052944 -0.9850079 ]\n",
      "iter 319 lare=0.648059\n",
      "    ang_loss=3.888034\n",
      "    e_l=4.725302 e_r=2.832136\n",
      "[-0.2471881   0.19881397 -0.9483518 ]\n",
      "[-0.16761339  0.18899456 -0.96756744]\n",
      "iter 320 lare=0.923627\n",
      "    ang_loss=4.834785\n",
      "    e_l=1.538624 e_r=2.427532\n",
      "[ 0.05112307  0.22143474 -0.9738343 ]\n",
      "[ 0.07192083  0.20460925 -0.97619796]\n",
      "iter 321 lare=1.001628\n",
      "    ang_loss=5.040915\n",
      "    e_l=7.737636 e_r=4.926088\n",
      "[ 0.13485935  0.27985355 -0.95052356]\n",
      "[ 0.04449549  0.18463638 -0.9817991 ]\n",
      "iter 322 lare=0.816276\n",
      "    ang_loss=5.008889\n",
      "    e_l=4.173824 e_r=3.367727\n",
      "[-0.20291364  0.08870474 -0.97517055]\n",
      "[-0.18987954  0.16006461 -0.9686718 ]\n",
      "iter 323 lare=1.406051\n",
      "    ang_loss=5.142039\n",
      "    e_l=6.820672 e_r=3.980395\n",
      "[ 0.11594184  0.1199318  -0.98598886]\n",
      "[ 0.05361275  0.22054945 -0.97390133]\n",
      "iter 324 lare=0.871417\n",
      "    ang_loss=6.040942\n",
      "    e_l=6.510840 e_r=1.689686\n",
      "[ 0.10048119  0.19287425 -0.97606516]\n",
      "[-0.00532583  0.23397702 -0.9722276 ]\n",
      "iter 325 lare=0.629493\n",
      "    ang_loss=5.718008\n",
      "    e_l=6.666180 e_r=2.895635\n",
      "[-0.2623053   0.07073361 -0.9623891 ]\n",
      "[-0.23922898  0.18433991 -0.9533039 ]\n",
      "iter 326 lare=0.593027\n",
      "    ang_loss=5.930271\n",
      "    e_l=5.927776 e_r=2.712599\n",
      "[ 0.03962926  0.19794783 -0.9794112 ]\n",
      "[ 0.04433523  0.29796445 -0.9535469 ]\n",
      "iter 327 lare=1.142138\n",
      "    ang_loss=6.441212\n",
      "    e_l=7.348495 e_r=0.536683\n",
      "[ 0.09024245  0.17888923 -0.9797219 ]\n",
      "[ 0.0958067  0.3029871 -0.9481666]\n",
      "iter 328 lare=2.278070\n",
      "    ang_loss=7.458892\n",
      "    e_l=14.829687 e_r=7.938252\n",
      "[ 0.12908168  0.02493977 -0.9913204 ]\n",
      "[ 0.05479704  0.27028412 -0.96121985]\n",
      "iter 329 lare=0.820245\n",
      "    ang_loss=8.202453\n",
      "    e_l=4.878091 e_r=3.075998\n",
      "[ 0.02593209  0.23924433 -0.9706131 ]\n",
      "[-7.6788006e-04  3.1695923e-01 -9.4843876e-01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 330 lare=0.853242\n",
      "    ang_loss=7.065866\n",
      "    e_l=7.519195 e_r=5.777739\n",
      "[ 0.07620016  0.20536625 -0.97571427]\n",
      "[ 0.01347271  0.3172122  -0.94825894]\n",
      "iter 331 lare=0.853821\n",
      "    ang_loss=7.537776\n",
      "    e_l=11.223105 e_r=3.856864\n",
      "[-0.19671507  0.13893047 -0.9705677 ]\n",
      "[-0.08103145  0.29550466 -0.9518986 ]\n",
      "iter 332 lare=1.175723\n",
      "    ang_loss=6.786675\n",
      "    e_l=11.315482 e_r=6.077799\n",
      "[ 0.18421325  0.08394878 -0.9792948 ]\n",
      "[ 0.10342816  0.2626991  -0.95931846]\n",
      "iter 333 lare=1.260169\n",
      "    ang_loss=5.742251\n",
      "    e_l=9.984576 e_r=1.852768\n",
      "[ 0.05355139  0.07583197 -0.99568164]\n",
      "[ 0.08236187  0.24489675 -0.9660446 ]\n",
      "iter 334 lare=0.991953\n",
      "    ang_loss=6.267968\n",
      "    e_l=8.438057 e_r=4.830388\n",
      "[-0.17517667  0.06338421 -0.98249465]\n",
      "[-0.1326735   0.2036971  -0.97000283]\n",
      "iter 335 lare=1.645205\n",
      "    ang_loss=6.079825\n",
      "    e_l=3.109546 e_r=1.882632\n",
      "[-0.16519727  0.14199011 -0.97598606]\n",
      "[-0.12404208  0.17735696 -0.9762981 ]\n",
      "iter 336 lare=0.811219\n",
      "    ang_loss=5.160236\n",
      "    e_l=2.863753 e_r=0.834391\n",
      "[-0.27628288  0.13239038 -0.95191425]\n",
      "[-0.23350726  0.11073706 -0.9660288 ]\n",
      "iter 337 lare=1.021696\n",
      "    ang_loss=4.438042\n",
      "    e_l=1.975263 e_r=1.484376\n",
      "[-0.08961489  0.21518973 -0.97245187]\n",
      "[-0.05898689  0.20034783 -0.97794753]\n",
      "iter 338 lare=1.913246\n",
      "    ang_loss=5.639857\n",
      "    e_l=10.434676 e_r=7.327291\n",
      "[-0.12988214  0.0997938  -0.9864948 ]\n",
      "[ 0.02632533  0.19276741 -0.98089135]\n",
      "iter 339 lare=1.326702\n",
      "    ang_loss=4.209005\n",
      "    e_l=8.952033 e_r=7.644521\n",
      "[-0.13688764  0.17401083 -0.9751831 ]\n",
      "[ 0.01816919  0.16047433 -0.9868729 ]\n",
      "iter 340 lare=0.460493\n",
      "    ang_loss=4.140957\n",
      "    e_l=0.545364 e_r=2.448805\n",
      "[-0.06172943  0.10998426 -0.99201465]\n",
      "[-0.05909088  0.10090558 -0.9931396 ]\n",
      "iter 341 lare=0.959665\n",
      "    ang_loss=3.497932\n",
      "    e_l=2.781997 e_r=3.150078\n",
      "[-0.01501668  0.10397884 -0.9944662 ]\n",
      "[ 0.00919223  0.14574157 -0.9892799 ]\n",
      "iter 342 lare=1.571524\n",
      "    ang_loss=4.231325\n",
      "    e_l=1.543323 e_r=3.691729\n",
      "[-0.20468158  0.05572209 -0.97724134]\n",
      "[-0.21970402  0.07757444 -0.97247756]\n",
      "iter 343 lare=1.220345\n",
      "    ang_loss=4.142793\n",
      "    e_l=4.710687 e_r=3.664900\n",
      "[-0.23070544  0.11726584 -0.9659316 ]\n",
      "[-0.15182097  0.10186875 -0.9831446 ]\n",
      "iter 344 lare=0.851675\n",
      "    ang_loss=4.735680\n",
      "    e_l=8.714425 e_r=6.452422\n",
      "[-0.15045358  0.2593767  -0.9539851 ]\n",
      "[-0.12727208  0.11254227 -0.98546237]\n",
      "iter 345 lare=1.192510\n",
      "    ang_loss=5.184405\n",
      "    e_l=9.005339 e_r=9.063688\n",
      "[ 0.08007906  0.02259557 -0.99653244]\n",
      "[-0.07459396  0.0495874  -0.9959803 ]\n",
      "iter 346 lare=0.857418\n",
      "    ang_loss=4.834553\n",
      "    e_l=3.810588 e_r=4.548810\n",
      "[-0.0865148   0.10562743 -0.9906352 ]\n",
      "[-0.03842181  0.06021202 -0.997446  ]\n",
      "iter 347 lare=1.582336\n",
      "    ang_loss=4.819255\n",
      "    e_l=3.578561 e_r=4.335218\n",
      "[-0.16709071  0.06099812 -0.9840529 ]\n",
      "[-0.10527135  0.059084   -0.99268675]\n",
      "iter 348 lare=1.498145\n",
      "    ang_loss=5.589115\n",
      "    e_l=7.919436 e_r=7.017581\n",
      "[-0.15348269  0.17843747 -0.971907  ]\n",
      "[-0.1102097   0.04894011 -0.9927027 ]\n",
      "iter 349 lare=0.791728\n",
      "    ang_loss=5.102960\n",
      "    e_l=5.675059 e_r=2.722683\n",
      "[-0.03450077  0.18596353 -0.9819508 ]\n",
      "[-0.00907263  0.09128144 -0.99578375]\n",
      "iter 350 lare=1.755667\n",
      "    ang_loss=6.935676\n",
      "    e_l=3.930193 e_r=3.697717\n",
      "[-0.14217915 -0.0069819  -0.98981637]\n",
      "[-0.15431339  0.06041844 -0.98617285]\n",
      "iter 351 lare=2.195826\n",
      "    ang_loss=6.693174\n",
      "    e_l=13.182303 e_r=12.513199\n",
      "[ 0.13949226  0.2066005  -0.9684308 ]\n",
      "[-0.05911896  0.09429794 -0.99378705]\n",
      "iter 352 lare=0.513778\n",
      "    ang_loss=4.436797\n",
      "    e_l=6.384326 e_r=4.921871\n",
      "[ 0.16362444  0.00299275 -0.9865182 ]\n",
      "[ 0.09012166  0.08647095 -0.99216974]\n",
      "iter 353 lare=1.143022\n",
      "    ang_loss=6.224889\n",
      "    e_l=2.357089 e_r=2.663372\n",
      "[-0.17886697  0.01611366 -0.98374134]\n",
      "[-0.16343698  0.05422267 -0.9850625 ]\n",
      "iter 354 lare=1.118434\n",
      "    ang_loss=4.756235\n",
      "    e_l=1.369165 e_r=0.619920\n",
      "[ 0.0998406   0.14258106 -0.9847348 ]\n",
      "[ 0.07612529  0.14491588 -0.9865111 ]\n",
      "iter 355 lare=1.441761\n",
      "    ang_loss=4.284420\n",
      "    e_l=6.313450 e_r=4.488731\n",
      "[-0.15550417  0.01598409 -0.98770595]\n",
      "[-0.08201161  0.09790974 -0.9918104 ]\n",
      "iter 356 lare=0.824799\n",
      "    ang_loss=4.775135\n",
      "    e_l=20.533564 e_r=17.023724\n",
      "[ 0.16882141  0.25290415 -0.9526484 ]\n",
      "[-0.14439717  0.08598229 -0.9857771 ]\n",
      "iter 357 lare=0.817596\n",
      "    ang_loss=4.821835\n",
      "    e_l=9.522704 e_r=7.835989\n",
      "[ 0.08450137  0.05507313 -0.9949003 ]\n",
      "[-0.08063446  0.07208552 -0.99413365]\n",
      "iter 358 lare=0.783300\n",
      "    ang_loss=4.357807\n",
      "    e_l=4.176826 e_r=1.946217\n",
      "[-0.06112292  0.25796875 -0.96421796]\n",
      "[-0.06055772  0.18693075 -0.98050475]\n",
      "iter 359 lare=0.764609\n",
      "    ang_loss=4.276726\n",
      "    e_l=5.950714 e_r=3.853562\n",
      "[-0.05326596  0.0050787  -0.9985675 ]\n",
      "[-0.01441622  0.10127267 -0.9947542 ]\n",
      "iter 360 lare=1.467280\n",
      "    ang_loss=4.686610\n",
      "    e_l=0.181308 e_r=1.675146\n",
      "[-0.04778921  0.11290953 -0.9924554 ]\n",
      "[-0.04989565  0.11054228 -0.99261814]\n",
      "iter 361 lare=0.870437\n",
      "    ang_loss=4.376892\n",
      "    e_l=7.669230 e_r=5.590580\n",
      "[ 0.12941174  0.00875938 -0.9915523 ]\n",
      "[ 0.03232476  0.10071564 -0.99438995]\n",
      "iter 362 lare=0.682567\n",
      "    ang_loss=5.518960\n",
      "    e_l=6.023499 e_r=5.067283\n",
      "[-0.02528441  0.02306048 -0.9994143 ]\n",
      "[-0.1286438   0.03997979 -0.9908846 ]\n",
      "iter 363 lare=1.593546\n",
      "    ang_loss=5.169285\n",
      "    e_l=3.452186 e_r=3.530972\n",
      "[-0.06594399  0.0152376  -0.997707  ]\n",
      "[-0.06974272  0.07528672 -0.99472   ]\n",
      "iter 364 lare=1.280078\n",
      "    ang_loss=5.997979\n",
      "    e_l=10.813612 e_r=8.075331\n",
      "[ 0.15950334  0.05003005 -0.9859289 ]\n",
      "[-0.01804098  0.11276778 -0.99345756]\n",
      "iter 365 lare=1.012107\n",
      "    ang_loss=4.514159\n",
      "    e_l=3.444351 e_r=2.592538\n",
      "[ 0.16582525  0.17714018 -0.9701152 ]\n",
      "[ 0.10712615  0.1885508  -0.97620314]\n",
      "iter 366 lare=1.106196\n",
      "    ang_loss=2.834914\n",
      "    e_l=3.640724 e_r=2.076883\n",
      "[-0.02632588  0.05460548 -0.99816096]\n",
      "[-0.06252954  0.10648844 -0.9923458 ]\n",
      "iter 367 lare=1.663589\n",
      "    ang_loss=3.870744\n",
      "    e_l=9.508409 e_r=7.166178\n",
      "[ 0.18707794  0.27162376 -0.94404584]\n",
      "[ 0.05762467  0.17560506 -0.98277277]\n",
      "iter 368 lare=1.919230\n",
      "    ang_loss=5.081930\n",
      "    e_l=4.070396 e_r=3.599129\n",
      "[-0.09536708  0.26858374 -0.95852387]\n",
      "[-0.09573279  0.19954303 -0.9752014 ]\n",
      "iter 369 lare=1.174102\n",
      "    ang_loss=3.414349\n",
      "    e_l=2.373143 e_r=2.379733\n",
      "[-0.12249399  0.11384757 -0.98591787]\n",
      "[-0.14735492  0.1460707  -0.97823817]\n",
      "iter 370 lare=1.374492\n",
      "    ang_loss=4.717291\n",
      "    e_l=3.061134 e_r=1.930365\n",
      "[ 0.1539716   0.16362137 -0.97443366]\n",
      "[ 0.10135739  0.17097734 -0.98004764]\n",
      "iter 371 lare=1.833631\n",
      "    ang_loss=4.580129\n",
      "    e_l=5.604340 e_r=4.128155\n",
      "[-0.12707984  0.2288537  -0.96513045]\n",
      "[-0.11733479  0.1334299  -0.9840879 ]\n",
      "iter 372 lare=0.941431\n",
      "    ang_loss=4.849140\n",
      "    e_l=9.055035 e_r=7.653502\n",
      "[ 0.07198096  0.02189537 -0.99716574]\n",
      "[ 0.02922497  0.1733376  -0.9844288 ]\n",
      "iter 373 lare=1.219601\n",
      "    ang_loss=3.769766\n",
      "    e_l=8.077908 e_r=5.239029\n",
      "[ 0.1884272  0.0467705 -0.9809729]\n",
      "[ 0.09061228  0.14807092 -0.98481697]\n",
      "iter 374 lare=0.956965\n",
      "    ang_loss=3.227062\n",
      "    e_l=1.118901 e_r=2.128632\n",
      "[ 0.11578294  0.10469883 -0.9877412 ]\n",
      "[ 0.10497376  0.12095373 -0.987092  ]\n",
      "iter 375 lare=1.713572\n",
      "    ang_loss=4.594051\n",
      "    e_l=4.718291 e_r=3.130816\n",
      "[ 0.09575342  0.20766795 -0.9735016 ]\n",
      "[ 0.07961308  0.12834905 -0.9885284 ]\n",
      "iter 376 lare=1.450425\n",
      "    ang_loss=4.709320\n",
      "    e_l=7.068799 e_r=5.659946\n",
      "[-0.19422936  0.24713446 -0.94931537]\n",
      "[-0.20046593  0.126022   -0.97156155]\n",
      "iter 377 lare=2.334381\n",
      "    ang_loss=3.651711\n",
      "    e_l=3.084134 e_r=3.888114\n",
      "[ 0.03265081  0.13354887 -0.99050426]\n",
      "[ 0.0392059   0.08040887 -0.99599063]\n",
      "iter 378 lare=0.737486\n",
      "    ang_loss=3.928463\n",
      "    e_l=6.674911 e_r=5.785638\n",
      "[-0.01291413  0.02468312 -0.999612  ]\n",
      "[-0.0534119   0.13338925 -0.98962337]\n",
      "iter 379 lare=1.234263\n",
      "    ang_loss=3.954988\n",
      "    e_l=8.942986 e_r=9.106297\n",
      "[ 0.15950334  0.05003005 -0.9859289 ]\n",
      "[ 0.02673602  0.1316454  -0.99093634]\n",
      "iter 380 lare=0.820463\n",
      "    ang_loss=4.822793\n",
      "    e_l=8.420980 e_r=5.695777\n",
      "[-0.1079409   0.05031535 -0.9928833 ]\n",
      "[ 0.01828896  0.12533335 -0.99194604]\n",
      "iter 381 lare=1.881213\n",
      "    ang_loss=5.810309\n",
      "    e_l=4.704320 e_r=4.917570\n",
      "[-0.05647438  0.15568037 -0.98619187]\n",
      "[ 0.02423895  0.14115654 -0.9896906 ]\n",
      "iter 382 lare=1.193261\n",
      "    ang_loss=5.580940\n",
      "    e_l=2.749368 e_r=3.550933\n",
      "[-0.01888196  0.08891528 -0.9958603 ]\n",
      "[ 0.01902434  0.11817618 -0.9928104 ]\n",
      "iter 383 lare=1.108764\n",
      "    ang_loss=5.604672\n",
      "    e_l=4.000075 e_r=4.231469\n",
      "[-0.25422874  0.09377788 -0.96258694]\n",
      "[-0.18634312  0.10063728 -0.97731704]\n",
      "iter 384 lare=0.747138\n",
      "    ang_loss=4.776926\n",
      "    e_l=5.924932 e_r=4.118275\n",
      "[-0.00165091  0.01732192 -0.99984866]\n",
      "[-0.03611901  0.1145119  -0.99276507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 385 lare=1.684233\n",
      "    ang_loss=4.037228\n",
      "    e_l=3.131379 e_r=2.595330\n",
      "[ 0.10543746  0.16640323 -0.9804045 ]\n",
      "[ 0.15855673  0.15469192 -0.9751565 ]\n",
      "iter 386 lare=1.448293\n",
      "    ang_loss=4.062025\n",
      "    e_l=6.288058 e_r=3.886804\n",
      "[ 0.07983303  0.1598351  -0.9839103 ]\n",
      "[ 0.18821175  0.14922464 -0.97072566]\n",
      "iter 387 lare=1.220379\n",
      "    ang_loss=4.655259\n",
      "    e_l=5.289168 e_r=3.641854\n",
      "[ 0.03271635  0.2675235  -0.9629958 ]\n",
      "[-0.01168317  0.18887284 -0.98193204]\n",
      "iter 388 lare=1.170246\n",
      "    ang_loss=4.419191\n",
      "    e_l=3.016555 e_r=2.468072\n",
      "[ 0.15082347  0.19893764 -0.9683368 ]\n",
      "[ 0.10189545  0.18207681 -0.9779905 ]\n",
      "iter 389 lare=0.515804\n",
      "    ang_loss=4.048747\n",
      "    e_l=3.123053 e_r=2.279244\n",
      "[ 0.05355139  0.07583197 -0.99568164]\n",
      "[ 0.01772561  0.11681876 -0.9929951 ]\n",
      "iter 390 lare=1.159752\n",
      "    ang_loss=5.510861\n",
      "    e_l=13.413123 e_r=12.332798\n",
      "[ 0.15671179  0.21674208 -0.96356857]\n",
      "[-0.06233498  0.13951793 -0.98825556]\n",
      "iter 391 lare=1.362279\n",
      "    ang_loss=5.409636\n",
      "    e_l=2.753992 e_r=1.664481\n",
      "[-0.26626045  0.09115781 -0.959581  ]\n",
      "[-0.28337017  0.13492152 -0.9494723 ]\n",
      "iter 392 lare=1.027379\n",
      "    ang_loss=4.460789\n",
      "    e_l=7.479999 e_r=3.530529\n",
      "[-0.1457527  -0.00461933 -0.9893103 ]\n",
      "[-0.22087958  0.10029726 -0.97013026]\n",
      "iter 393 lare=1.168170\n",
      "    ang_loss=5.583914\n",
      "    e_l=3.714676 e_r=2.287559\n",
      "[ 0.11815878  0.1773933  -0.9770211 ]\n",
      "[ 0.06291535  0.21127012 -0.97540075]\n",
      "iter 394 lare=0.878624\n",
      "    ang_loss=4.155438\n",
      "    e_l=4.800528 e_r=3.431708\n",
      "[ 0.02973105  0.13226306 -0.99076873]\n",
      "[-0.04578667  0.1679944  -0.98472416]\n",
      "iter 395 lare=0.965157\n",
      "    ang_loss=5.198225\n",
      "    e_l=7.837593 e_r=3.171076\n",
      "[-0.04359567  0.0646134  -0.9969577 ]\n",
      "[-0.15336555  0.1437397  -0.97765934]\n",
      "iter 396 lare=1.252823\n",
      "    ang_loss=5.255478\n",
      "    e_l=8.275570 e_r=6.224535\n",
      "[ 0.09776269  0.28159997 -0.95453864]\n",
      "[-0.04525041  0.26441684 -0.9633463 ]\n",
      "iter 397 lare=0.686919\n",
      "    ang_loss=6.869190\n",
      "    e_l=10.803359 e_r=9.330118\n",
      "[ 0.12035581  0.23475498 -0.9645749 ]\n",
      "[-0.06755956  0.24616806 -0.9668698 ]\n",
      "iter 398 lare=0.634374\n",
      "    ang_loss=6.343738\n",
      "    e_l=9.494651 e_r=5.506340\n",
      "[-0.15117434  0.01005227 -0.9884561 ]\n",
      "[-0.2425791   0.14492315 -0.9592459 ]\n",
      "iter 399 lare=0.662815\n",
      "    ang_loss=4.708259\n",
      "    e_l=8.871591 e_r=3.725256\n",
      "[-0.16407496 -0.00511171 -0.9864347 ]\n",
      "[-0.24211721  0.12618935 -0.96200603]\n",
      "iter 400 lare=0.858191\n",
      "    ang_loss=5.996590\n",
      "    e_l=4.085859 e_r=3.251368\n",
      "[-0.03450077  0.18596353 -0.9819508 ]\n",
      "[-0.07743711  0.24100177 -0.96743053]\n",
      "iter 401 lare=0.580824\n",
      "    ang_loss=5.808237\n",
      "    e_l=9.491048 e_r=6.333263\n",
      "[-0.12988214  0.0997938  -0.9864948 ]\n",
      "[-0.04636237  0.24158661 -0.96927106]\n",
      "iter 402 lare=0.729743\n",
      "    ang_loss=5.460945\n",
      "    e_l=9.396889 e_r=6.030491\n",
      "[ 0.16256723  0.08586311 -0.9829545 ]\n",
      "[ 0.16453871  0.24725075 -0.9548791 ]\n",
      "iter 403 lare=0.791054\n",
      "    ang_loss=4.772597\n",
      "    e_l=3.979264 e_r=2.276495\n",
      "[-0.01258062  0.25920105 -0.9657415 ]\n",
      "[-0.07488037  0.22891268 -0.9705628 ]\n",
      "iter 404 lare=1.613887\n",
      "    ang_loss=5.369608\n",
      "    e_l=6.764106 e_r=4.705944\n",
      "[ 0.07988554  0.12004072 -0.9895497 ]\n",
      "[ 0.11324528  0.23081698 -0.9663844 ]\n",
      "iter 405 lare=1.905503\n",
      "    ang_loss=5.885970\n",
      "    e_l=1.959846 e_r=1.431355\n",
      "[ 0.1532148   0.20095249 -0.9675451 ]\n",
      "[ 0.17998122  0.22032322 -0.95867854]\n",
      "iter 406 lare=2.246034\n",
      "    ang_loss=5.574601\n",
      "    e_l=9.096085 e_r=5.182663\n",
      "[-0.04011397  0.03038986 -0.9987329 ]\n",
      "[ 0.04244695  0.16513282 -0.9853575 ]\n",
      "iter 407 lare=1.487774\n",
      "    ang_loss=4.737154\n",
      "    e_l=4.437561 e_r=1.757026\n",
      "[ 0.13701175  0.15550938 -0.9782866 ]\n",
      "[ 0.2015995  0.1941245 -0.9600382]\n",
      "iter 408 lare=2.159387\n",
      "    ang_loss=4.847355\n",
      "    e_l=5.858960 e_r=4.340095\n",
      "[ 0.060689    0.15620019 -0.9858593 ]\n",
      "[ 0.1484983   0.20515394 -0.96739864]\n",
      "iter 409 lare=1.881764\n",
      "    ang_loss=4.728719\n",
      "    e_l=5.755987 e_r=3.273870\n",
      "[-0.07128249  0.15179807 -0.9858379 ]\n",
      "[ 0.02691126  0.17278746 -0.9845914 ]\n",
      "iter 410 lare=1.653874\n",
      "    ang_loss=5.408310\n",
      "    e_l=14.380993 e_r=13.209112\n",
      "[-0.20292023  0.10513726 -0.97353464]\n",
      "[ 0.04477098  0.13776758 -0.98945224]\n",
      "iter 411 lare=1.647388\n",
      "    ang_loss=5.179627\n",
      "    e_l=5.074894 e_r=3.517917\n",
      "[-0.20937385  0.14914212 -0.966395  ]\n",
      "[-0.12247054  0.14280178 -0.98214495]\n",
      "iter 412 lare=0.946651\n",
      "    ang_loss=3.705603\n",
      "    e_l=2.727926 e_r=1.519426\n",
      "[ 0.09884957  0.11851805 -0.9880194 ]\n",
      "[ 0.14239539  0.13618459 -0.9803965 ]\n",
      "iter 413 lare=0.883678\n",
      "    ang_loss=3.690497\n",
      "    e_l=3.319655 e_r=1.261140\n",
      "[-0.18454215  0.15391974 -0.97069716]\n",
      "[-0.1273253   0.15458731 -0.97974026]\n",
      "iter 414 lare=1.150763\n",
      "    ang_loss=3.490226\n",
      "    e_l=8.987409 e_r=10.015041\n",
      "[ 0.1441315   0.10898132 -0.98353916]\n",
      "[ 0.0029847   0.17703997 -0.98419917]\n",
      "iter 415 lare=1.155700\n",
      "    ang_loss=3.735609\n",
      "    e_l=5.183079 e_r=3.831139\n",
      "[-0.1525732   0.19174804 -0.96951234]\n",
      "[-0.10534343  0.11677045 -0.9875563 ]\n",
      "iter 416 lare=0.720857\n",
      "    ang_loss=3.668089\n",
      "    e_l=2.610220 e_r=2.251685\n",
      "[-0.24005787  0.18387209 -0.9531859 ]\n",
      "[-0.21244493  0.14983763 -0.9656169 ]\n",
      "iter 417 lare=1.313403\n",
      "    ang_loss=4.338941\n",
      "    e_l=4.498016 e_r=1.537097\n",
      "[ 0.02622165  0.09949734 -0.9946923 ]\n",
      "[-0.05217589  0.10296164 -0.993316  ]\n",
      "iter 418 lare=1.137814\n",
      "    ang_loss=4.410521\n",
      "    e_l=5.085615 e_r=5.262762\n",
      "[-0.25346807  0.23250586 -0.9389862 ]\n",
      "[-0.20941836  0.1598868  -0.9646658 ]\n",
      "iter 419 lare=0.536621\n",
      "    ang_loss=4.345522\n",
      "    e_l=5.903222 e_r=5.568521\n",
      "[-0.24301541  0.25337544 -0.93634635]\n",
      "[-0.22380948  0.15553983 -0.96214175]\n",
      "iter 420 lare=1.233337\n",
      "    ang_loss=4.518945\n",
      "    e_l=4.436413 e_r=4.312025\n",
      "[ 0.03096598  0.2606108  -0.9649473 ]\n",
      "[-0.01282677  0.19857743 -0.9800013 ]\n",
      "iter 421 lare=1.194596\n",
      "    ang_loss=4.296984\n",
      "    e_l=9.190155 e_r=7.273432\n",
      "[-0.1010187   0.01814947 -0.994719  ]\n",
      "[-0.1620125   0.16470468 -0.9729462 ]\n",
      "iter 422 lare=0.770952\n",
      "    ang_loss=4.503814\n",
      "    e_l=13.067764 e_r=8.445385\n",
      "[ 1.6376716e-01  5.7668757e-04 -9.8649889e-01]\n",
      "[ 0.02514125  0.18103524 -0.98315525]\n",
      "iter 423 lare=0.822963\n",
      "    ang_loss=5.886650\n",
      "    e_l=6.393226 e_r=3.143795\n",
      "[ 0.11932111  0.0766139  -0.9898954 ]\n",
      "[ 0.06826545  0.17546114 -0.9821167 ]\n",
      "iter 424 lare=0.840145\n",
      "    ang_loss=5.588295\n",
      "    e_l=9.660315 e_r=6.253572\n",
      "[ 0.14686035  0.2628629  -0.95359075]\n",
      "[-0.01677045  0.22834335 -0.9734363 ]\n",
      "iter 425 lare=0.655339\n",
      "    ang_loss=6.553392\n",
      "    e_l=7.332858 e_r=3.662601\n",
      "[ 0.02619772  0.11488926 -0.9930329 ]\n",
      "[-0.02878683  0.22862712 -0.9730884 ]\n",
      "iter 426 lare=0.906149\n",
      "    ang_loss=6.272029\n",
      "    e_l=5.088196 e_r=1.649719\n",
      "[-0.26767966  0.12909195 -0.95482093]\n",
      "[-0.28488663  0.21376415 -0.9344221 ]\n",
      "iter 427 lare=0.991431\n",
      "    ang_loss=5.720484\n",
      "    e_l=6.025418 e_r=3.933779\n",
      "[-0.21410404  0.19240503 -0.9576742 ]\n",
      "[-0.18771517  0.29218656 -0.937758  ]\n",
      "iter 428 lare=0.629605\n",
      "    ang_loss=6.296052\n",
      "    e_l=8.354350 e_r=2.301548\n",
      "[ 0.11594184  0.1199318  -0.98598886]\n",
      "[ 0.08776842  0.26073593 -0.9614123 ]\n",
      "iter 429 lare=0.788650\n",
      "    ang_loss=5.868630\n",
      "    e_l=7.591169 e_r=1.388326\n",
      "[-0.17627229  0.109985   -0.97817767]\n",
      "[-0.17283684  0.24032173 -0.9551821 ]\n",
      "iter 430 lare=1.467939\n",
      "    ang_loss=5.157432\n",
      "    e_l=3.694380 e_r=3.247813\n",
      "[ 0.16746373  0.17653185 -0.9699446 ]\n",
      "[ 0.13736174  0.23308136 -0.9627071 ]\n",
      "iter 431 lare=0.557862\n",
      "    ang_loss=5.142827\n",
      "    e_l=0.555671 e_r=5.774583\n",
      "[ 0.09718851  0.2548499  -0.96208423]\n",
      "[ 0.08764666  0.25661266 -0.96253216]\n",
      "iter 432 lare=1.104216\n",
      "    ang_loss=4.667152\n",
      "    e_l=5.958483 e_r=3.746536\n",
      "[ 0.0921002   0.13798152 -0.9861434 ]\n",
      "[ 0.17002714  0.2032045  -0.96426076]\n",
      "iter 433 lare=0.822580\n",
      "    ang_loss=5.119315\n",
      "    e_l=6.897536 e_r=5.205222\n",
      "[-0.22303781  0.22459961 -0.94858277]\n",
      "[-0.10956345  0.26334444 -0.95846003]\n",
      "iter 434 lare=0.810394\n",
      "    ang_loss=4.890321\n",
      "    e_l=1.758251 e_r=2.879568\n",
      "[ 0.15207168  0.2356134  -0.95987535]\n",
      "[ 0.15539777  0.20576277 -0.9661849 ]\n",
      "iter 435 lare=1.272309\n",
      "    ang_loss=5.142815\n",
      "    e_l=4.883349 e_r=3.417931\n",
      "[ 0.06632412  0.1280999  -0.9895411 ]\n",
      "[ 0.06242985  0.21201086 -0.97527117]\n",
      "iter 436 lare=1.342028\n",
      "    ang_loss=5.860572\n",
      "    e_l=9.977878 e_r=10.884809\n",
      "[ 0.00811347  0.27674446 -0.96090937]\n",
      "[-0.14820418  0.20084907 -0.9683466 ]\n",
      "iter 437 lare=1.240187\n",
      "    ang_loss=4.390152\n",
      "    e_l=4.551522 e_r=1.781142\n",
      "[-0.2316853   0.16567087 -0.9585798 ]\n",
      "[-0.16625696  0.21043085 -0.96336776]\n",
      "iter 438 lare=0.789491\n",
      "    ang_loss=3.966114\n",
      "    e_l=4.122268 e_r=2.735665\n",
      "[-0.12122808  0.2219184  -0.9674999 ]\n",
      "[-0.06013884  0.18629342 -0.98065174]\n",
      "iter 439 lare=0.839458\n",
      "    ang_loss=4.713688\n",
      "    e_l=1.910903 e_r=1.201056\n",
      "[ 0.16887566  0.15807883 -0.97287834]\n",
      "[ 0.13699682  0.16726588 -0.9763474 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 440 lare=2.582705\n",
      "    ang_loss=5.552190\n",
      "    e_l=1.573709 e_r=2.893809\n",
      "[ 0.11301076  0.22131011 -0.96863335]\n",
      "[ 0.11219462  0.19447446 -0.9744703 ]\n",
      "iter 441 lare=1.946528\n",
      "    ang_loss=3.448708\n",
      "    e_l=1.709033 e_r=0.976787\n",
      "[ 0.05191118  0.16126241 -0.9855454 ]\n",
      "[ 0.03897724  0.18782689 -0.98142856]\n",
      "iter 442 lare=1.655464\n",
      "    ang_loss=3.985500\n",
      "    e_l=1.913564 e_r=1.482265\n",
      "[-0.03443738  0.24772088 -0.9682193 ]\n",
      "[-0.04145618  0.21589673 -0.9755358 ]\n",
      "iter 443 lare=0.561769\n",
      "    ang_loss=4.459485\n",
      "    e_l=6.754734 e_r=4.472557\n",
      "[ 0.10387819  0.03478807 -0.9939815 ]\n",
      "[ 0.05804998  0.14316966 -0.9879943 ]\n",
      "iter 444 lare=0.906053\n",
      "    ang_loss=5.630291\n",
      "    e_l=1.583626 e_r=2.271244\n",
      "[-0.19772467  0.20005839 -0.95962584]\n",
      "[-0.21784393  0.217189   -0.9515109 ]\n",
      "iter 445 lare=0.513116\n",
      "    ang_loss=5.131161\n",
      "    e_l=5.690096 e_r=2.324142\n",
      "[-0.15889694  0.17764461 -0.97118187]\n",
      "[-0.25599155  0.17244093 -0.95117426]\n",
      "iter 446 lare=1.079945\n",
      "    ang_loss=7.122087\n",
      "    e_l=5.978354 e_r=3.219904\n",
      "[-0.05105621  0.12183805 -0.99123603]\n",
      "[-0.12841344  0.18949057 -0.9734491 ]\n",
      "iter 447 lare=1.022657\n",
      "    ang_loss=6.287132\n",
      "    e_l=9.903732 e_r=7.569138\n",
      "[-0.0761834   0.21861404 -0.97283304]\n",
      "[-0.24563809  0.22970602 -0.94175214]\n",
      "iter 448 lare=0.758842\n",
      "    ang_loss=5.719613\n",
      "    e_l=3.920764 e_r=3.006219\n",
      "[-0.13688764  0.17401083 -0.9751831 ]\n",
      "[-0.2017139   0.15359016 -0.96732706]\n",
      "iter 449 lare=1.095810\n",
      "    ang_loss=8.061058\n",
      "    e_l=13.811242 e_r=7.594994\n",
      "[ 0.15487449  0.2755457  -0.94873   ]\n",
      "[-0.07093118  0.19807096 -0.9776178 ]\n",
      "iter 450 lare=0.615942\n",
      "    ang_loss=6.159423\n",
      "    e_l=3.989241 e_r=2.173939\n",
      "[ 0.00394919  0.22257936 -0.9749066 ]\n",
      "[-0.06551306  0.21817982 -0.97370714]\n",
      "iter 451 lare=0.923037\n",
      "    ang_loss=5.786941\n",
      "    e_l=7.228788 e_r=2.231954\n",
      "[ 0.01698345  0.20899975 -0.97776824]\n",
      "[-0.10798168  0.2231432  -0.9687865 ]\n",
      "iter 452 lare=0.837239\n",
      "    ang_loss=5.657203\n",
      "    e_l=1.628707 e_r=6.603043\n",
      "[-0.1328791   0.24354252 -0.9607447 ]\n",
      "[-0.13383074  0.21587557 -0.96720576]\n",
      "iter 453 lare=1.440070\n",
      "    ang_loss=6.136406\n",
      "    e_l=2.507177 e_r=3.411567\n",
      "[-0.13862237  0.24417238 -0.9597728 ]\n",
      "[-0.16343822  0.20841552 -0.9642878 ]\n",
      "iter 454 lare=0.793851\n",
      "    ang_loss=5.417936\n",
      "    e_l=9.589520 e_r=2.796664\n",
      "[ 0.06203414  0.10044333 -0.99300706]\n",
      "[-0.07025193  0.2013934  -0.9769879 ]\n",
      "iter 455 lare=0.874097\n",
      "    ang_loss=4.702907\n",
      "    e_l=3.357771 e_r=7.323889\n",
      "[-0.20724736  0.17600729 -0.96232533]\n",
      "[-0.17065598  0.22171733 -0.96006143]\n",
      "iter 456 lare=1.226504\n",
      "    ang_loss=4.999932\n",
      "    e_l=6.269041 e_r=3.833949\n",
      "[ 0.08342422  0.06895516 -0.9941256 ]\n",
      "[ 0.06389669  0.17590916 -0.9823304 ]\n",
      "iter 457 lare=2.119634\n",
      "    ang_loss=4.109860\n",
      "    e_l=1.135222 e_r=2.432365\n",
      "[ 0.02290216  0.16441254 -0.9861258 ]\n",
      "[ 0.01615665  0.18278947 -0.98301935]\n",
      "iter 458 lare=0.695331\n",
      "    ang_loss=3.916287\n",
      "    e_l=3.227435 e_r=2.705952\n",
      "[-0.04727368  0.11356508 -0.9924053 ]\n",
      "[-0.01169918  0.15695915 -0.98753583]\n",
      "iter 459 lare=1.233018\n",
      "    ang_loss=3.540753\n",
      "    e_l=5.011101 e_r=3.899078\n",
      "[-0.05275417  0.21701375 -0.9747421 ]\n",
      "[-0.01661306  0.1389087  -0.9901658 ]\n",
      "iter 460 lare=1.380998\n",
      "    ang_loss=3.431485\n",
      "    e_l=3.271297 e_r=3.488070\n",
      "[-0.22707735  0.03113022 -0.97337914]\n",
      "[-0.2243513   0.08808243 -0.9705194 ]\n",
      "iter 461 lare=1.991569\n",
      "    ang_loss=4.901512\n",
      "    e_l=2.616362 e_r=3.196410\n",
      "[-0.21003182 -0.00506392 -0.9776815 ]\n",
      "[-0.22544804  0.03771615 -0.9735249 ]\n",
      "iter 462 lare=1.022062\n",
      "    ang_loss=5.552762\n",
      "    e_l=8.493453 e_r=3.563098\n",
      "[-0.14856131  0.24170853 -0.9589091 ]\n",
      "[-0.03275149  0.15393983 -0.9875373 ]\n",
      "iter 463 lare=0.865693\n",
      "    ang_loss=4.446856\n",
      "    e_l=5.287649 e_r=1.524826\n",
      "[-0.11442585  0.06169881 -0.991514  ]\n",
      "[-0.02243878  0.05899991 -0.9980058 ]\n",
      "iter 464 lare=0.725787\n",
      "    ang_loss=5.253244\n",
      "    e_l=12.024918 e_r=9.783336\n",
      "[-0.09846282  0.2810691  -0.95462316]\n",
      "[ 0.00801639  0.10510409 -0.99442893]\n",
      "iter 465 lare=0.626736\n",
      "    ang_loss=6.267363\n",
      "    e_l=6.507466 e_r=4.099258\n",
      "[-0.15195014  0.18072459 -0.9717252 ]\n",
      "[-0.09859568  0.08253969 -0.99169856]\n",
      "iter 466 lare=0.900891\n",
      "    ang_loss=5.091288\n",
      "    e_l=6.571875 e_r=4.343162\n",
      "[ 0.067656    0.09921479 -0.9927634 ]\n",
      "[ 0.01311738 -0.00136659 -0.9999131 ]\n",
      "iter 467 lare=0.579438\n",
      "    ang_loss=5.529943\n",
      "    e_l=6.563066 e_r=4.716173\n",
      "[ 0.07059512  0.11012837 -0.99140716]\n",
      "[ 0.15920548  0.03780371 -0.9865213 ]\n",
      "iter 468 lare=0.724486\n",
      "    ang_loss=4.996788\n",
      "    e_l=0.323247 e_r=2.938249\n",
      "[-0.00667959  0.05567669 -0.99842656]\n",
      "[-0.01229692  0.05506798 -0.9984069 ]\n",
      "iter 469 lare=0.635252\n",
      "    ang_loss=4.201561\n",
      "    e_l=3.737640 e_r=2.265636\n",
      "[-0.00165091  0.01732192 -0.99984866]\n",
      "[-0.06318167  0.03879932 -0.9972475 ]\n",
      "iter 470 lare=0.669109\n",
      "    ang_loss=5.056275\n",
      "    e_l=10.419940 e_r=4.415569\n",
      "[-0.0822669   0.23431459 -0.9686738 ]\n",
      "[-0.0940669   0.05487236 -0.99405247]\n",
      "iter 471 lare=0.829906\n",
      "    ang_loss=4.123472\n",
      "    e_l=0.572666 e_r=1.593113\n",
      "[ 0.07476723  0.10722563 -0.9914195 ]\n",
      "[ 0.07091372  0.09807374 -0.99264944]\n",
      "iter 472 lare=1.846403\n",
      "    ang_loss=4.415281\n",
      "    e_l=6.259244 e_r=3.764472\n",
      "[ 0.10402697  0.24195655 -0.96469456]\n",
      "[ 0.10685387  0.13472737 -0.98510444]\n",
      "iter 473 lare=0.912561\n",
      "    ang_loss=4.370065\n",
      "    e_l=4.568789 e_r=3.669651\n",
      "[-0.14927876  0.1237444  -0.9810216 ]\n",
      "[-0.11226636  0.05402862 -0.99220824]\n",
      "iter 474 lare=1.439412\n",
      "    ang_loss=3.169130\n",
      "    e_l=6.697321 e_r=5.985759\n",
      "[-0.22271456  0.23404445 -0.94637287]\n",
      "[-0.19990584  0.12240261 -0.9721396 ]\n",
      "iter 475 lare=1.720558\n",
      "    ang_loss=3.921092\n",
      "    e_l=1.762253 e_r=1.251483\n",
      "[ 0.1203958   0.22833857 -0.9661089 ]\n",
      "[ 0.14041671  0.20512496 -0.96861076]\n",
      "iter 476 lare=1.824841\n",
      "    ang_loss=3.315307\n",
      "    e_l=1.380410 e_r=0.790558\n",
      "[-0.06792849  0.0690641  -0.99529696]\n",
      "[-0.06707406  0.09306964 -0.9933978 ]\n",
      "iter 477 lare=0.655581\n",
      "    ang_loss=3.314470\n",
      "    e_l=1.664364 e_r=0.920474\n",
      "[-0.20031308  0.13654462 -0.97017026]\n",
      "[-0.17179687  0.13855448 -0.97534025]\n",
      "iter 478 lare=1.194255\n",
      "    ang_loss=3.266440\n",
      "    e_l=2.825908 e_r=3.074216\n",
      "[-0.26895124  0.11763414 -0.9559433 ]\n",
      "[-0.2550877   0.16485472 -0.95276076]\n",
      "iter 479 lare=2.222129\n",
      "    ang_loss=5.090519\n",
      "    e_l=3.658215 e_r=3.434332\n",
      "[ 0.14239979  0.13574317 -0.9804571 ]\n",
      "[ 0.10857341  0.18968418 -0.97582364]\n",
      "iter 480 lare=1.524151\n",
      "    ang_loss=3.322205\n",
      "    e_l=5.448774 e_r=3.000679\n",
      "[ 0.17959712  0.0599772  -0.9819102 ]\n",
      "[ 0.12487691  0.137709   -0.98256904]\n",
      "iter 481 lare=0.991017\n",
      "    ang_loss=3.583817\n",
      "    e_l=1.946419 e_r=1.538242\n",
      "[ 0.09575342  0.20766795 -0.9735016 ]\n",
      "[ 0.09057949  0.17481323 -0.9804263 ]\n",
      "iter 482 lare=0.899659\n",
      "    ang_loss=4.008902\n",
      "    e_l=6.705574 e_r=4.933361\n",
      "[-0.14160943  0.11892363 -0.98275334]\n",
      "[-0.02999876  0.15356733 -0.98768264]\n",
      "iter 483 lare=2.357499\n",
      "    ang_loss=4.524907\n",
      "    e_l=8.580505 e_r=7.014813\n",
      "[-0.01291413  0.02468312 -0.999612  ]\n",
      "[ 0.00260452  0.17277178 -0.98495847]\n",
      "iter 484 lare=2.258460\n",
      "    ang_loss=4.574515\n",
      "    e_l=6.157306 e_r=3.623960\n",
      "[ 0.16939287  0.09811447 -0.9806527 ]\n",
      "[ 0.11630349  0.19129738 -0.97461736]\n",
      "iter 485 lare=1.202283\n",
      "    ang_loss=4.231137\n",
      "    e_l=3.907506 e_r=2.558414\n",
      "[-0.04281812  0.14468908 -0.98855036]\n",
      "[-0.10804343  0.12494235 -0.9862637 ]\n",
      "iter 486 lare=1.509552\n",
      "    ang_loss=3.062549\n",
      "    e_l=2.474171 e_r=2.328433\n",
      "[-0.00789795  0.21458633 -0.9766731 ]\n",
      "[-0.05103596  0.2129865  -0.97572124]\n",
      "iter 487 lare=1.183408\n",
      "    ang_loss=4.013689\n",
      "    e_l=5.722486 e_r=4.922268\n",
      "[ 0.11594184  0.1199318  -0.98598886]\n",
      "[ 0.03864181  0.18300731 -0.9823518 ]\n",
      "iter 488 lare=1.588024\n",
      "    ang_loss=4.373633\n",
      "    e_l=1.892275 e_r=2.124306\n",
      "[ 0.06441449  0.16104493 -0.98484284]\n",
      "[ 0.03249708  0.16953431 -0.9849884 ]\n",
      "iter 489 lare=0.989707\n",
      "    ang_loss=4.274330\n",
      "    e_l=3.960321 e_r=3.894153\n",
      "[-0.0512654   0.08474808 -0.9950828 ]\n",
      "[-0.11487495  0.11058852 -0.9872051 ]\n",
      "iter 490 lare=0.722834\n",
      "    ang_loss=3.521065\n",
      "    e_l=8.225690 e_r=5.112934\n",
      "[ 0.05642705  0.01070354 -0.9983494 ]\n",
      "[-0.07918919  0.05733269 -0.9952096 ]\n",
      "iter 491 lare=2.303774\n",
      "    ang_loss=6.864154\n",
      "    e_l=8.964425 e_r=6.662325\n",
      "[ 0.02633796  0.27011293 -0.9624684 ]\n",
      "[-0.06642646  0.14672218 -0.9869449 ]\n",
      "iter 492 lare=2.177537\n",
      "    ang_loss=7.136679\n",
      "    e_l=1.497371 e_r=2.002911\n",
      "[-0.00267227  0.02702154 -0.99963135]\n",
      "[-0.02847483  0.02287365 -0.9993328 ]\n",
      "iter 493 lare=1.357603\n",
      "    ang_loss=4.485795\n",
      "    e_l=7.001518 e_r=5.668666\n",
      "[ 0.17332254  0.23651566 -0.9560438 ]\n",
      "[ 0.13263479  0.12464086 -0.9832968 ]\n",
      "iter 494 lare=0.464598\n",
      "    ang_loss=3.559887\n",
      "    e_l=4.939512 e_r=3.064905\n",
      "[ 0.07614605  0.1633518  -0.983625  ]\n",
      "[-0.00968852  0.17096151 -0.98523015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 495 lare=1.260057\n",
      "    ang_loss=4.217935\n",
      "    e_l=9.406422 e_r=7.372939\n",
      "[ 0.14678337  0.10806771 -0.98324776]\n",
      "[-0.01292525  0.14478186 -0.98937917]\n",
      "iter 496 lare=0.830478\n",
      "    ang_loss=3.582618\n",
      "    e_l=6.997622 e_r=6.880881\n",
      "[-0.14428644  0.03318242 -0.9889795 ]\n",
      "[-0.1826182  0.1478135 -0.9720091]\n",
      "iter 497 lare=1.222334\n",
      "    ang_loss=4.574414\n",
      "    e_l=2.306814 e_r=0.260196\n",
      "[-0.01035973  0.22030288 -0.97537655]\n",
      "[-0.02799336  0.18479434 -0.9823784 ]\n",
      "iter 498 lare=1.217557\n",
      "    ang_loss=3.666104\n",
      "    e_l=2.624877 e_r=1.875028\n",
      "[ 0.08747622  0.17937706 -0.9798836 ]\n",
      "[ 0.12062016  0.14780171 -0.9816341 ]\n",
      "iter 499 lare=1.077786\n",
      "    ang_loss=3.924717\n",
      "    e_l=4.610869 e_r=2.203981\n",
      "[-0.02479122  0.21544708 -0.9762008 ]\n",
      "[-0.00767662  0.13812552 -0.99038494]\n",
      "iter 500 lare=0.840436\n",
      "    ang_loss=5.071321\n",
      "    e_l=5.521693 e_r=3.590360\n",
      "[-0.08957852  0.15392095 -0.98401433]\n",
      "[-0.00104145  0.11705891 -0.9931245 ]\n",
      "train over\n",
      "finalloss=1.401728\n",
      "finalangloss=3.220872\n"
     ]
    }
   ],
   "source": [
    "rate = 0.005\n",
    "training_iters = 500\n",
    "batch_size = 16\n",
    "beta = 0.1\n",
    "display_step = 10\n",
    "k = tf.Graph()\n",
    "with k.as_default():\n",
    "    input_l = tf.placeholder(tf.float32, [None, 36*60], name='L_img')\n",
    "    input_r = tf.placeholder(tf.float32, [None, 36*60], name='R_img')\n",
    "    input_g = tf.placeholder(tf.float32, [None, 6], name='gaze')\n",
    "    input_p = tf.placeholder(tf.float32, [None, 6], name='pose')\n",
    "    trainset = get_train_dataset()\n",
    "    testset = get_test_dataset()\n",
    "    with tf.name_scope('AR_Net'):\n",
    "        gaze = ARNet(input_l, input_r, input_p)\n",
    "        f_l = gaze[:,0:3]\n",
    "        f_l = tf.math.divide(f_l, tenlen(f_l))\n",
    "        f_r = gaze[:,3:6]\n",
    "        f_r = tf.math.divide(f_r, tenlen(f_r))\n",
    "        g_l = input_g[:,0:3]\n",
    "        g_l = tf.math.divide(g_l, tenlen(g_l))\n",
    "        g_r = input_g[:,3:6]\n",
    "        g_r = tf.math.divide(g_r, tenlen(g_r))\n",
    "        with tf.name_scope('AR_loss'):\n",
    "            e_l = tf.math.acos(tf.reduce_sum(f_l*g_l, axis=1))/np.pi*180\n",
    "            e_r = tf.math.acos(tf.reduce_sum(f_r*g_r, axis=1))/np.pi*180\n",
    "            Lar = tf.math.divide(2*(e_l*e_r),(e_l+e_r))\n",
    "    with tf.name_scope('E_Net'):\n",
    "        prob = ENet(input_l, input_r)\n",
    "        p_l = prob[:,0:1]\n",
    "        p_l = tf.reshape(p_l, [-1])\n",
    "        p_r = prob[:,1:2]\n",
    "        p_r = tf.reshape(p_r, [-1])\n",
    "        with tf.name_scope('E_loss'):\n",
    "            e = tf.math.acos(tf.reduce_sum(f_l*f_r, axis=1))\n",
    "            nu = tf.greater(e_r, e_l)\n",
    "            nu = tf.cast(nu, dtype=tf.float32)\n",
    "            Le = -1*(nu*e*tf.math.log(p_l)+(1-nu)*e*tf.math.log(p_r))\n",
    "    with tf.name_scope('ARE_loss'):``\n",
    "        w = (1+(2*nu-1)*p_l+(1-2*nu)*p_r)/2\n",
    "        Lare = w*Lar+(1-w)*beta*(e_l+e_r)/2\n",
    "        Lare = tf.reduce_mean(Lare)\n",
    "    with tf.name_scope('angular_loss'):\n",
    "        ang_loss = tf.reduce_mean((e_l+e_r)/2)\n",
    "    with tf.name_scope('op_Lare'):\n",
    "        op_Lare = tf.train.AdamOptimizer(learning_rate=rate).minimize(Lare)\n",
    "    with tf.name_scope('op_Le'):\n",
    "        op_Le = tf.train.AdamOptimizer(learning_rate=rate).minimize(Le)\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter('log/', sess.graph)\n",
    "        loss_summary = tf.summary.scalar('loss', Lare)\n",
    "        sess.run(init)\n",
    "        step = 1\n",
    "        while step<=training_iters:\n",
    "            batch = sess.run(trainset)\n",
    "            #print(batch['gaze'][0])\n",
    "            sess.run(op_Lare, feed_dict={\n",
    "                input_l:batch['img_l'],\n",
    "                input_r:batch['img_r'],\n",
    "                input_g:batch['gaze'],\n",
    "                input_p:batch['pose']\n",
    "            })\n",
    "            '''\n",
    "            sess.run(op_Le, feed_dict={\n",
    "                input_l:batch['img_l'],\n",
    "                input_r:batch['img_r'],\n",
    "                input_g:batch['gaze'],\n",
    "                input_p:batch['pose']\n",
    "            })\n",
    "            '''\n",
    "            [e_ll, e_rr] = sess.run([e_l, e_r],\n",
    "                feed_dict={\n",
    "                    input_l:batch['img_l'],\n",
    "                    input_r:batch['img_r'],\n",
    "                    input_g:batch['gaze'],\n",
    "                    input_p:batch['pose']\n",
    "                })\n",
    "            [lare, le, acc] = sess.run([Lare, Le, ang_loss],\n",
    "                feed_dict={\n",
    "                    input_l:batch['img_l'],\n",
    "                    input_r:batch['img_r'],\n",
    "                    input_g:batch['gaze'],\n",
    "                    input_p:batch['pose']\n",
    "                })\n",
    "            [f_ll, g_ll] = sess.run([f_l, g_l],\n",
    "                feed_dict={\n",
    "                    input_l:batch['img_l'],\n",
    "                    input_r:batch['img_r'],\n",
    "                    input_g:batch['gaze'],\n",
    "                    input_p:batch['pose']\n",
    "                })\n",
    "            #if step%display_step==0:\n",
    "            print('iter '+str(step)+' lare='+'{:.6f}'.format(lare))\n",
    "            #print('    le='+'{:.6f}'.format(le))\n",
    "            print('    ang_loss='+'{:.6f}'.format(acc))\n",
    "            print('    e_l='+'{:.6f}'.format(e_ll[0])+' e_r='+'{:.6f}'.format(e_rr[0]))\n",
    "            print(g_ll[0])\n",
    "            print(f_ll[0])\n",
    "            #print(''+'{:.6f}'.format(g_ll[0][0]))\n",
    "            #print('    func='+'{:.6f}'.format(f_ll[0][0]))\n",
    "            step += 1\n",
    "        batch = sess.run(testset)\n",
    "        print('train over')\n",
    "        [finalloss, finalacc] = sess.run([Lare, ang_loss], feed_dict={\n",
    "                input_l:batch['img_l'],\n",
    "                input_r:batch['img_r'],\n",
    "                input_g:batch['gaze'],\n",
    "                input_p:batch['pose']\n",
    "        })\n",
    "        print('finalloss='+'{:.6f}'.format(finalloss))\n",
    "        print('finalangloss='+'{:.6f}'.format(finalacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
